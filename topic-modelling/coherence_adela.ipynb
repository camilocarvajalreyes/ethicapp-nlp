{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Número óptimo de Tópicos con métrica Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 rows found with non string elements for column comment (0.40%)\n",
      "Deleting 685 columns for which max target value is over 7 (10.58%)\n",
      "5761 available rows after processing\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.cargar import df_caso\n",
    "from utils.preprocesamiento import process_df, procesar_adela, StemmerTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizador = StemmerTokenizer(stem=False,rmv_punctuation=True)\n",
    "\n",
    "caso = 'adela'\n",
    "\n",
    "df = df_caso(caso)\n",
    "df = procesar_adela(df)\n",
    "df = df[df['opt_left'] == 'Producir el alimento contra déficit vitamínico']\n",
    "df = process_df(df,'comment','sel',verbose=True)\n",
    "df = df.drop(columns=['user_id','team_id','gender','df','title','opt_left','opt_right','max_num','phase','time','curso'])\n",
    "\n",
    "df_train, df_test, _, _ = train_test_split(df, df['sel'], test_size=.05, stratify=df['sel'], random_state=0)\n",
    "tokenized_corpus = [tokenizador(document) for document in df_train['comment']]\n",
    "tokenized_test = [tokenizador(document) for document in df_test['comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Create a dictionary from the tokenized corpus\n",
    "dictionary = corpora.Dictionary(tokenized_corpus)\n",
    "\n",
    "# Convert the tokenized corpus into a document-term matrix\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in tokenized_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of topics: 4\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Set the range of topic numbers to try\n",
    "min_topics = 2\n",
    "max_topics = 10\n",
    "step_size = 1\n",
    "\n",
    "# Initialize variables for best coherence score and best number of topics\n",
    "best_coherence_score = -1\n",
    "best_num_topics = -1\n",
    "\n",
    "# Iterate over the range of topic numbers\n",
    "for num_topics in range(min_topics, max_topics+1, step_size):\n",
    "    # Train the LDA model\n",
    "    lda_model = gensim.models.LdaModel(doc_term_matrix, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "    \n",
    "    # Calculate coherence score\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=tokenized_corpus, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    \n",
    "    # Check if coherence score is the best so far\n",
    "    if coherence_score > best_coherence_score:\n",
    "        best_coherence_score = coherence_score\n",
    "        best_num_topics = num_topics\n",
    "\n",
    "# Print the best number of topics\n",
    "print(f\"Best number of topics: {best_num_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.7 s, sys: 15.9 ms, total: 16.7 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model_opt = gensim.models.LdaModel(doc_term_matrix, num_topics=best_num_topics, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.022*\"tradiciones\" + 0.015*\"alimento\" + 0.014*\"pueblo\" + 0.013*\"si\" + 0.012*\"importante\" + 0.012*\"pueblos\" + 0.011*\"puede\" + 0.011*\"acuerdo\" + 0.010*\"llegar\" + 0.010*\"mas\"')\n",
      "(1, '0.019*\"pueblo\" + 0.015*\"fruta\" + 0.013*\"producción\" + 0.012*\"debe\" + 0.011*\"proyecto\" + 0.010*\"tradiciones\" + 0.009*\"comunidad\" + 0.009*\"debería\" + 0.008*\"puede\" + 0.008*\"Adela\"')\n",
      "(2, '0.031*\"tradiciones\" + 0.029*\"alimento\" + 0.024*\"pueblo\" + 0.017*\"importante\" + 0.015*\"personas\" + 0.015*\"producir\" + 0.013*\"originario\" + 0.011*\"producción\" + 0.011*\"llegar\" + 0.011*\"acuerdo\"')\n",
      "(3, '0.028*\"tradiciones\" + 0.018*\"vitamina\" + 0.012*\"D\" + 0.012*\"salud\" + 0.009*\"si\" + 0.008*\"importante\" + 0.008*\"pueblo\" + 0.008*\"personas\" + 0.007*\"fruta\" + 0.007*\"población\"')\n"
     ]
    }
   ],
   "source": [
    "# Print the generated topics\n",
    "topics = lda_model_opt.print_topics(num_topics=num_topics)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se debe priorizar respetar gente pueblo insistir cantidad gente beneficiaria fruta llegar acuerdo beneficie bandos problema\n",
      "\n",
      "Topic 0: 0.01584179513156414\n",
      "Topic 1: 0.23093238472938538\n",
      "Topic 2: 0.7381098866462708\n",
      "Topic 3: 0.015115933492779732\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(tokenized_test[0]) + '\\n')\n",
    "\n",
    "# Convert the tokenized document into a document-term matrix\n",
    "doc_term_matrix = [dictionary.doc2bow(tokenized_test[0])]\n",
    "\n",
    "# Get the topic probabilities for the new document\n",
    "topic_probs = lda_model_opt.get_document_topics(doc_term_matrix)[0]\n",
    "\n",
    "# Print the topic probabilities\n",
    "for topic, prob in topic_probs:\n",
    "    print(f\"Topic {topic}: {prob}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethics_env",
   "language": "python",
   "name": "ethics_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
