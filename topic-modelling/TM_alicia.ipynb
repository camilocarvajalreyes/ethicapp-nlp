{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelamiento no supervisado en base a tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.preprocesamiento import StemmerTokenizer\n",
    "\n",
    "tokenizador = StemmerTokenizer(stem=False,rmv_punctuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 rows found with non string elements for column comment (0.65%)\n",
      "Deleting 2326 columns for which max target value is over 7 (18.76%)\n",
      "9991 available rows after processing\n"
     ]
    }
   ],
   "source": [
    "from utils.cargar import df_caso\n",
    "from utils.preprocesamiento import process_df\n",
    "\n",
    "caso = 'alicia'\n",
    "df = df_caso(caso)\n",
    "\n",
    "df = process_df(df,'comment','sel',verbose=True)\n",
    "\n",
    "df = df.drop(columns=['user_id','team_id','gender','df','title','opt_left','opt_right','max_num','phase','time','curso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test, _, _ = train_test_split(df, df['sel'], test_size=.05, stratify=df['sel'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [tokenizador(document) for document in df_train['comment']]\n",
    "tokenized_test = [tokenizador(document) for document in df_test['comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Create a dictionary from the tokenized corpus\n",
    "dictionary = corpora.Dictionary(tokenized_corpus)\n",
    "\n",
    "# Convert the tokenized corpus into a document-term matrix\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in tokenized_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Número óptimo de tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of topics: 4\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Set the range of topic numbers to try\n",
    "min_topics = 2\n",
    "max_topics = 10\n",
    "step_size = 1\n",
    "\n",
    "# Initialize variables for best coherence score and best number of topics\n",
    "best_coherence_score = -1\n",
    "best_num_topics = -1\n",
    "\n",
    "# Iterate over the range of topic numbers\n",
    "for num_topics in range(min_topics, max_topics+1, step_size):\n",
    "    # Train the LDA model\n",
    "    lda_model = gensim.models.LdaModel(doc_term_matrix, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "    \n",
    "    # Calculate coherence score\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=tokenized_corpus, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    \n",
    "    # Check if coherence score is the best so far\n",
    "    if coherence_score > best_coherence_score:\n",
    "        best_coherence_score = coherence_score\n",
    "        best_num_topics = num_topics\n",
    "\n",
    "# Print the best number of topics\n",
    "print(f\"Best number of topics: {best_num_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 3.77 ms, total: 22 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model = gensim.models.LdaModel(doc_term_matrix, num_topics=2, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.042*\"proyecto\" + 0.015*\"entregar\" + 0.015*\"cumplir\" + 0.013*\"plazos\" + 0.013*\"Alicia\" + 0.013*\"si\" + 0.013*\"criterios\" + 0.012*\"debe\" + 0.011*\"plazo\" + 0.011*\"importante\"')\n",
      "(1, '0.018*\"reputación\" + 0.018*\"ser\" + 0.017*\"si\" + 0.015*\"proyecto\" + 0.013*\"usuarios\" + 0.013*\"transparencia\" + 0.009*\"Alicia\" + 0.009*\"puede\" + 0.009*\"importante\" + 0.009*\"mantener\"')\n"
     ]
    }
   ],
   "source": [
    "# Print the generated topics\n",
    "topics = lda_model.print_topics(num_topics=2)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es importante producir producto aceptable incluso si demora pues hacer producto mal puede llevar repercuciones grandes\n",
      "\n",
      "Topic 0: 0.5650599598884583\n",
      "Topic 1: 0.43494001030921936\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(tokenized_test[0]) + '\\n')\n",
    "\n",
    "# Convert the tokenized document into a document-term matrix\n",
    "doc_term_matrix = [dictionary.doc2bow(tokenized_test[0])]\n",
    "\n",
    "# Get the topic probabilities for the new document\n",
    "topic_probs = lda_model.get_document_topics(doc_term_matrix)[0]\n",
    "\n",
    "# Print the topic probabilities\n",
    "for topic, prob in topic_probs:\n",
    "    print(f\"Topic {topic}: {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el168841397631644130566840345015\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el168841397631644130566840345015_data = {\"mdsDat\": {\"x\": [0.11096266611314629, -0.11096266611314629], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [56.50584866123941, 43.494151338760595]}, \"tinfo\": {\"Term\": [\"reputaci\\u00f3n\", \"cumplir\", \"transparencia\", \"plazos\", \"criterios\", \"t\\u00e9cnicos\", \"entregar\", \"mantener\", \"transparente\", \"contexto\", \"profesional\", \"mandante\", \"falencias\", \"ser\", \"proyecto\", \"calidad\", \"La\", \"acuerdos\", \"personal\", \"condiciones\", \"plazo\", \"atraso\", \"tiempo\", \"pandemia\", \"acordados\", \"posible\", \"necesidades\", \"fallas\", \"confianza\", \"grupo\", \"criterios\", \"plazos\", \"t\\u00e9cnicos\", \"contexto\", \"acuerdos\", \"condiciones\", \"cumplir\", \"pandemia\", \"acordados\", \"necesidades\", \"mundial\", \"atraso\", \"contingencia\", \"cumpla\", \"contrato\", \"contextuales\", \"sanciones\", \"satisfacer\", \"requerimientos\", \"multas\", \"acordado\", \"tecnicos\", \"establecidos\", \"atrasos\", \"fecha\", \"actual\", \"tiempos\", \"salud\", \"adaptarse\", \"entender\", \"entregarlo\", \"completo\", \"demora\", \"entregar\", \"especificaciones\", \"calidad\", \"respetar\", \"posible\", \"plazo\", \"tiempo\", \"proyecto\", \"buen\", \"entrega\", \"priorizar\", \"deber\\u00eda\", \"debe\", \"bien\", \"Alicia\", \"trabajo\", \"importante\", \"mejor\", \"si\", \"puede\", \"producto\", \"mas\", \"usuario\", \"usuarios\", \"hacer\", \"ser\", \"tener\", \"reputaci\\u00f3n\", \"transparencia\", \"transparente\", \"mandante\", \"personal\", \"falencias\", \"profesional\", \"confianza\", \"reputacion\", \"faltas\", \"valores\", \"informaci\\u00f3n\", \"verdad\", \"honestidad\", \"mantener\", \"omitir\", \"empresarial\", \"honesta\", \"afectada\", \"imagen\", \"honesto\", \"ocultar\", \"universidad\", \"Mantengo\", \"mantiene\", \"llegamos\", \"mentir\", \"\\u00e9tica\", \"actuar\", \"Mi\", \"postura\", \"La\", \"fallos\", \"t\\u00e9cnicas\", \"falla\", \"peor\", \"saber\", \"responsable\", \"2\", \"grupo\", \"fallas\", \"ser\", \"persona\", \"futuro\", \"usuarios\", \"si\", \"empresa\", \"respecto\", \"usuario\", \"puede\", \"podr\\u00eda\", \"importante\", \"Alicia\", \"caso\", \"proyecto\", \"producto\", \"problemas\", \"debe\", \"tener\", \"mejor\", \"siempre\", \"trabajo\", \"deber\\u00eda\", \"bien\"], \"Freq\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11603895648877938, 0.12044428953404562, 0.09122415918865556, 0.07678018326529568, 0.05516558996706955, 0.046014005389485746, 0.13444972517335074, 0.03322057374587395, 0.03288106561340243, 0.03164728111198212, 0.02825126095421826, 0.037801910622670576, 0.0264079001533446, 0.025561902116168156, 0.020705430320936635, 0.01475875759303813, 0.01709273338956674, 0.017276619419192674, 0.01863575813017082, 0.02247567581438581, 0.023439899455471647, 0.016112968483014356, 0.01259861220848224, 0.014206721655433352, 0.01104441409159529, 0.010076719294237702, 0.01219442142596927, 0.008419802632546824, 0.007164901228804421, 0.008130881498094489, 0.024778351211773852, 0.01674148458147018, 0.01165486712639563, 0.1359165023563591, 0.015182913312882462, 0.0855460379703139, 0.01656810779847051, 0.05490753296909112, 0.09941639953099823, 0.09011464376576939, 0.3810675013456404, 0.03192738384654881, 0.05783470916439626, 0.09331910409148847, 0.089221245184671, 0.11168532241139317, 0.08391762152242066, 0.11757283286967635, 0.08073336926232244, 0.09893564964987789, 0.0750391236916208, 0.11609073965693284, 0.08203689895522359, 0.06830697082056325, 0.049897987181788395, 0.06317888788833947, 0.07401106361324139, 0.039036673952269396, 0.05763410201297248, 0.04227588373082902, 0.1274944713398085, 0.0892441181940562, 0.05604634647370377, 0.046176669124140535, 0.03521710493733288, 0.043546790456184814, 0.050838959936293504, 0.01970476326984605, 0.014761857204255158, 0.014934478952003394, 0.01407852538454435, 0.014392562222682592, 0.015101800752907457, 0.012071841719692444, 0.06032467225881577, 0.013681123347665802, 0.009266218207827637, 0.009257799215530993, 0.011653458633689717, 0.017032416975236164, 0.007053878458248286, 0.006467755943307535, 0.0060526685136426395, 0.007088620573880433, 0.006198027373711251, 0.0077763060949578855, 0.004991278814921174, 0.014517782580970029, 0.006011933780033368, 0.008302865778669066, 0.01909349355221246, 0.04132237797535021, 0.009290989909853664, 0.02028161006766782, 0.0149832689242968, 0.015366208311975993, 0.011767699951984456, 0.01096500266787842, 0.013859036940841452, 0.028935904773529364, 0.030822585392487056, 0.12583639001784164, 0.020825842181898535, 0.03806437378205074, 0.0898535067627182, 0.11712583745371763, 0.046057464877938825, 0.01953257413775278, 0.05503290460500354, 0.06228881214369597, 0.04297539105099224, 0.06199644821567318, 0.06306405939739523, 0.03230146985686355, 0.10139205004023877, 0.04554833944309444, 0.03043877915321458, 0.049511724271957824, 0.03223306797487835, 0.03727356208647281, 0.028592952358692525, 0.036767012902158, 0.0321401512057784, 0.03103604476183741], \"Total\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11609545423125794, 0.12051015400166784, 0.09127706808578961, 0.07684432602362568, 0.05521339906982263, 0.04606523681232892, 0.13460706840859807, 0.033269018945921144, 0.03293159296300149, 0.031710035730525735, 0.028307735974754507, 0.0378900809235926, 0.02647338984183244, 0.02563166956789898, 0.020768748766440567, 0.014805804374626435, 0.01714738751541854, 0.017333411819059712, 0.018701165817130896, 0.0225583896718771, 0.023526827290207403, 0.016175610453889624, 0.012654879155521633, 0.014271368106691917, 0.01109613848564829, 0.01013057509508939, 0.012262285000456953, 0.008477397927119368, 0.007214405594154465, 0.008188396082302565, 0.024970118430143948, 0.01691024299141808, 0.011737355979694884, 0.1428928227114004, 0.015362420442076273, 0.0900863020026661, 0.016867141217840692, 0.05890993057543151, 0.11118499468953463, 0.1014240635846348, 0.48245955138587915, 0.03407855303874263, 0.06657067506275366, 0.11576762440411414, 0.1213613963904494, 0.161197046683351, 0.11495366628425807, 0.18063689226707158, 0.11750038216448044, 0.16093209786555107, 0.11231268577809361, 0.23321657711065047, 0.14432571109891956, 0.1138553102636577, 0.07284514969597145, 0.11821179249334302, 0.16386457037595958, 0.04906645555054551, 0.18347049203081411, 0.07450895170570737, 0.1275296133270878, 0.08927745803441409, 0.05608074815022456, 0.04621795028574007, 0.03525515539446686, 0.04359642707239716, 0.05092950854030892, 0.019743296784935367, 0.014795706865345717, 0.014968742051648411, 0.01411389275967465, 0.014429409919201915, 0.015143539399918348, 0.012105270212906572, 0.06049640827121399, 0.013722931538017753, 0.009299013589400926, 0.009291466191218754, 0.011698048668690278, 0.01711200240763568, 0.007087408643438143, 0.006500203976140587, 0.006087272453774337, 0.007132775345270313, 0.006238134105950232, 0.007827719698737448, 0.00502457866220486, 0.01461710256756998, 0.006055671669620306, 0.008365255430786036, 0.019367770466572128, 0.04225276271061479, 0.009374387904321064, 0.020692690570444136, 0.015277686988083475, 0.015729539398838116, 0.011994762960879812, 0.0113314655115508, 0.014644159167056997, 0.03290982350913074, 0.03566015370008402, 0.18347049203081411, 0.02385532565629711, 0.04882672432521207, 0.16386457037595958, 0.23321657711065047, 0.07226710496248123, 0.023658597246651758, 0.11821179249334302, 0.14432571109891956, 0.08154102341366665, 0.16093209786555107, 0.18063689226707158, 0.05908872381706898, 0.48245955138587915, 0.1138553102636577, 0.05529513139327813, 0.161197046683351, 0.07450895170570737, 0.11231268577809361, 0.0557947411050006, 0.11750038216448044, 0.1213613963904494, 0.11495366628425807], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.3556, -4.3183, -4.5962, -4.7686, -5.0992, -5.2806, -4.2083, -5.6063, -5.6166, -5.6549, -5.7684, -5.4772, -5.8359, -5.8684, -6.0791, -6.4177, -6.2709, -6.2602, -6.1844, -5.9971, -5.9551, -6.3299, -6.5759, -6.4558, -6.7076, -6.7993, -6.6085, -6.9789, -7.1403, -7.0138, -5.8995, -6.2916, -6.6538, -4.1975, -6.3893, -4.6605, -6.302, -5.1039, -4.5102, -4.6084, -3.1665, -5.6461, -5.0519, -4.5735, -4.6184, -4.3938, -4.6797, -4.3425, -4.7184, -4.515, -4.7915, -4.3551, -4.7023, -4.8855, -5.1995, -4.9635, -4.8053, -5.445, -5.0554, -5.3653, -3.9997, -4.3564, -4.8216, -5.0153, -5.2863, -5.074, -4.9191, -5.8669, -6.1558, -6.1441, -6.2031, -6.1811, -6.133, -6.3569, -4.7481, -6.2318, -6.6214, -6.6223, -6.3922, -6.0127, -6.8942, -6.981, -7.0473, -6.8893, -7.0236, -6.7967, -7.2401, -6.1724, -7.0541, -6.7312, -5.8985, -5.1264, -6.6188, -5.8381, -6.1409, -6.1156, -6.3824, -6.4531, -6.2189, -5.4827, -5.4196, -4.0128, -5.8116, -5.2085, -4.3496, -4.0846, -5.0179, -5.8757, -4.8399, -4.716, -5.0872, -4.7207, -4.7036, -5.3727, -4.2288, -5.029, -5.4321, -4.9456, -5.3748, -5.2295, -5.4946, -5.2432, -5.3777, -5.4127], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5703, 0.5703, 0.5702, 0.57, 0.57, 0.5697, 0.5697, 0.5694, 0.5693, 0.5688, 0.5688, 0.5685, 0.5683, 0.5681, 0.5678, 0.5676, 0.5676, 0.5675, 0.5673, 0.5672, 0.5671, 0.5669, 0.5664, 0.5663, 0.5662, 0.5655, 0.5653, 0.564, 0.5639, 0.5638, 0.5631, 0.5608, 0.5638, 0.5208, 0.5591, 0.5191, 0.5529, 0.5005, 0.4589, 0.4526, 0.3349, 0.5056, 0.4302, 0.3553, 0.2632, 0.2039, 0.2561, 0.1414, 0.1955, 0.0843, 0.1675, -0.1268, 0.0059, 0.0599, 0.1925, -0.0557, -0.224, 0.3422, -0.5871, 0.0041, 0.8323, 0.8322, 0.8319, 0.8317, 0.8315, 0.8314, 0.8308, 0.8306, 0.8303, 0.8303, 0.83, 0.83, 0.8298, 0.8298, 0.8297, 0.8295, 0.829, 0.8289, 0.8287, 0.8279, 0.8278, 0.8275, 0.8268, 0.8263, 0.8261, 0.826, 0.8259, 0.8257, 0.8253, 0.8251, 0.8183, 0.8103, 0.8236, 0.8125, 0.8131, 0.8092, 0.8134, 0.7997, 0.7774, 0.7039, 0.6868, 0.4555, 0.6967, 0.5835, 0.2317, 0.1438, 0.3821, 0.6409, 0.068, -0.0077, 0.1921, -0.1214, -0.2198, 0.2286, -0.7274, -0.0836, 0.2356, -0.3479, -0.0054, -0.2705, 0.164, -0.3293, -0.4961, -0.4768]}, \"token.table\": {\"Topic\": [], \"Freq\": [], \"Term\": []}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el168841397631644130566840345015\", ldavis_el168841397631644130566840345015_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el168841397631644130566840345015\", ldavis_el168841397631644130566840345015_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el168841397631644130566840345015\", ldavis_el168841397631644130566840345015_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "vis_data = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TM_utils import get_lda_embeddings\n",
    "import pandas as pd\n",
    "\n",
    "arr_test = get_lda_embeddings(lda_model,tokenizador,dictionary,df_test,'comment')\n",
    "df_topics = pd.DataFrame(arr_test, columns=['Topic{}'.format(i+1) for i in range(len(topics))])\n",
    "\n",
    "df_topics['sel'] = df_test['sel'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-Target Correlations\n",
      "{'Topic1_sel': 0.35438077981334287, 'Topic2_sel': -0.35438078166882486}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Only compute pearson prod-moment correlations between feature\n",
    "# columns and target column\n",
    "target_col_name = 'sel'\n",
    "feature_target_corr = {}\n",
    "for col in df_topics:\n",
    "    if target_col_name != col:\n",
    "        feature_target_corr[col + '_' + target_col_name] = \\\n",
    "            pearsonr(df_topics[col], df_topics[target_col_name])[0]\n",
    "print(\"Feature-Target Correlations\")\n",
    "print(feature_target_corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethics_env",
   "language": "python",
   "name": "ethics_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
