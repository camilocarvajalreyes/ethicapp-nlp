{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelamiento no supervisado en base a tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utils.preprocesamiento import StemmerTokenizer\n",
    "\n",
    "tokenizador = StemmerTokenizer(stem=False,rmv_punctuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549 rows found with non string elements for column comment (11.03%)\n",
      "Deleting 362 columns for which max target value is over 7 (7.27%)\n",
      "4067 available rows after processing\n"
     ]
    }
   ],
   "source": [
    "from utils.cargar import df_caso\n",
    "from utils.preprocesamiento import process_df\n",
    "\n",
    "caso = 'laura'\n",
    "df = df_caso(caso)\n",
    "\n",
    "df = process_df(df,'comment','sel',verbose=True)\n",
    "\n",
    "df = df.drop(columns=['user_id','team_id','gender','df','title','opt_left','opt_right','max_num','phase','time','curso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test, _, _ = train_test_split(df, df['sel'], test_size=.05, stratify=df['sel'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_corpus = [tokenizador(document) for document in df_train['comment']]\n",
    "tokenized_test = [tokenizador(document) for document in df_test['comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Create a dictionary from the tokenized corpus\n",
    "dictionary = corpora.Dictionary(tokenized_corpus)\n",
    "\n",
    "# Convert the tokenized corpus into a document-term matrix\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in tokenized_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Número óptimo de tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of topics: 4\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Set the range of topic numbers to try\n",
    "min_topics = 2\n",
    "max_topics = 10\n",
    "step_size = 1\n",
    "\n",
    "# Initialize variables for best coherence score and best number of topics\n",
    "best_coherence_score = -1\n",
    "best_num_topics = -1\n",
    "\n",
    "# Iterate over the range of topic numbers\n",
    "for num_topics in range(min_topics, max_topics+1, step_size):\n",
    "    # Train the LDA model\n",
    "    lda_model = gensim.models.LdaModel(doc_term_matrix, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "    \n",
    "    # Calculate coherence score\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=tokenized_corpus, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    \n",
    "    # Check if coherence score is the best so far\n",
    "    if coherence_score > best_coherence_score:\n",
    "        best_coherence_score = coherence_score\n",
    "        best_num_topics = num_topics\n",
    "\n",
    "# Print the best number of topics\n",
    "print(f\"Best number of topics: {best_num_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 0 ns, total: 11.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda_model = gensim.models.LdaModel(doc_term_matrix, num_topics=best_num_topics, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.051*\"proyecto\" + 0.026*\"si\" + 0.016*\"renunciar\" + 0.012*\"impacto\" + 0.011*\"daño\" + 0.010*\"ambiente\" + 0.010*\"bien\" + 0.009*\"mejor\" + 0.009*\"Si\" + 0.009*\"correcto\"')\n",
      "(1, '0.014*\"errores\" + 0.014*\"si\" + 0.010*\"proyecto\" + 0.009*\"importante\" + 0.008*\"trabajo\" + 0.008*\"Laura\" + 0.007*\"No\" + 0.007*\"aprender\" + 0.006*\"ser\" + 0.006*\"frustración\"')\n",
      "(2, '0.037*\"trabajo\" + 0.036*\"tiempo\" + 0.030*\"familia\" + 0.022*\"vida\" + 0.014*\"debe\" + 0.014*\"importante\" + 0.013*\"si\" + 0.013*\"mas\" + 0.012*\"Laura\" + 0.011*\"bien\"')\n",
      "(3, '0.034*\"error\" + 0.017*\"errores\" + 0.015*\"si\" + 0.012*\"haber\" + 0.011*\"renunciar\" + 0.010*\"aprender\" + 0.010*\"adecuado\" + 0.009*\"No\" + 0.008*\"Laura\" + 0.008*\"trabajo\"')\n"
     ]
    }
   ],
   "source": [
    "# Print the generated topics\n",
    "topics = lda_model.print_topics(num_topics=num_topics)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personalmente encuentro importante vida personal trabajo dado pierden momentos realmente importan Sin embargo debe existir mínimo dedicación existir\n",
      "\n",
      "Topic 0: 0.08290089666843414\n",
      "Topic 1: 0.1859666109085083\n",
      "Topic 2: 0.7174871563911438\n",
      "Topic 3: 0.013645299710333347\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(tokenized_test[0]) + '\\n')\n",
    "\n",
    "# Convert the tokenized document into a document-term matrix\n",
    "doc_term_matrix = [dictionary.doc2bow(tokenized_test[0])]\n",
    "\n",
    "# Get the topic probabilities for the new document\n",
    "topic_probs = lda_model.get_document_topics(doc_term_matrix)[0]\n",
    "\n",
    "# Print the topic probabilities\n",
    "for topic, prob in topic_probs:\n",
    "    print(f\"Topic {topic}: {prob}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el139161399683683792646414605639\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el139161399683683792646414605639_data = {\"mdsDat\": {\"x\": [-0.1868624913924946, 0.008774954298659569, 0.11979044835083077, 0.05829708874300431], \"y\": [-0.03762432543528143, 0.022449573666856418, -0.13192014671148652, 0.14709489847991153], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [71.75116412036854, 18.59407541035914, 8.290229591061955, 1.3645308782103596]}, \"tinfo\": {\"Term\": [\"si\", \"proyecto\", \"Laura\", \"trabajo\", \"errores\", \"bien\", \"adecuado\", \"tiempo\", \"puede\", \"Si\", \"familia\", \"No\", \"creo\", \"mejor\", \"error\", \"renunciar\", \"solo\", \"decisi\\u00f3n\", \"aprender\", \"deber\\u00eda\", \"ser\", \"salud\", \"haber\", \"profesional\", \"pues\", \"mental\", \"vez\", \"mas\", \"correcto\", \"as\\u00ed\", \"equilibrio\", \"dedicar\", \"dimensiones\", \"ajustar\", \"dedique\", \"familia\", \"familiar\", \"dedicarle\", \"vivir\", \"dedicarse\", \"trabaja\", \"responsabilidades\", \"tiempo\", \"hijos\", \"dedica\", \"Debe\", \"equilibrar\", \"descuidar\", \"priorizar\", \"balance\", \"queridos\", \"feliz\", \"estr\\u00e9s\", \"gustar\\u00eda\", \"dedicaci\\u00f3n\", \"dedicado\", \"prioridades\", \"vive\", \"balancear\", \"ajuste\", \"vida\", \"salud\", \"mental\", \"pasar\", \"mantener\", \"trabajo\", \"(\", \")\", \"deber\\u00eda\", \"quiere\", \"aspectos\", \"mas\", \"debe\", \"padre\", \"personal\", \"lado\", \"importante\", \"bien\", \"Laura\", \"siempre\", \"puede\", \"dejar\", \"tener\", \"si\", \"Si\", \"persona\", \"Creo\", \"ser\", \"cometerlos\", \"sustentable\", \"presente\", \"ecol\\u00f3gico\", \"f\", \"frustraci\\u00f3n\", \"sacrificar\", \"sacar\", \"reci\\u00e9n\", \"planteara\", \"prefiere\", \"pros\", \"producido\", \"exista\", \"real\", \"trajo\", \"crecimiento\", \"compartir\", \"afectara\", \"intereses\", \"carga\", \"s\\u00e9\", \"retraso\", \"ayudar\\u00eda\", \"capaces\", \"llamado\", \"viviendo\", \"relacionado\", \"corregirse\", \"\\u00e1rea\", \"adecuada\", \"errores\", \"aprender\", \"tolerancia\", \"afrontar\", \"fracaso\", \"trae\", \"aprendizaje\", \"probablemente\", \"velar\", \"alternativas\", \"hoy\", \"beneficios\", \"jefe\", \"empleo\", \"mundo\", \"oportunidad\", \"error\", \"generar\", \"cargo\", \"El\", \"proyectos\", \"No\", \"mejorar\", \"parte\", \"proyecto\", \"si\", \"decisi\\u00f3n\", \"podr\\u00eda\", \"profesional\", \"Laura\", \"ser\", \"importante\", \"desarrollo\", \"mejor\", \"renunciar\", \"adecuado\", \"genera\", \"trabajo\", \"impacto\", \"laboral\", \"La\", \"debe\", \"puede\", \"tener\", \"Es\", \"as\\u00ed\", \"mas\", \"cada\", \"embargo\", \"medioambiente\", \"correcta\", \"ingenieros\", \"adentro\", \"ambiente\", \"valores\", \"medio\", \"renunciaron\", \"principios\", \"Renunciar\", \"negativo\", \"preventivas\", \"renuncien\", \"informaci\\u00f3n\", \"minimizar\", \"\\u00e9tico\", \"negativos\", \"renunciar\\u00eda\", \"consideran\", \"quieren\", \"quedarse\", \"posibles\", \"proponer\", \"empleos\", \"da\\u00f1ino\", \"participar\", \"alternativa\", \"creencias\", \"da\\u00f1o\", \"c\\u00f3modo\", \"ideas\", \"ecosistema\", \"ideales\", \"derecho\", \"proyecto\", \"impacto\", \"renunciar\", \"deber\\u00edan\", \"medidas\", \"pueden\", \"cambiar\", \"opci\\u00f3n\", \"va\", \"cambio\", \"parece\", \"ambiental\", \"si\", \"correcto\", \"mejor\", \"decisi\\u00f3n\", \"Si\", \"ser\", \"da\\u00f1os\", \"bien\", \"caso\", \"hacer\", \"acuerdo\", \"puede\", \"intentar\", \"posible\", \"creo\", \"debi\\u00f3\", \"sent\\u00eda\", \"cometi\\u00f3\", \"aprendido\", \"hizo\", \"distintas\", \"3\", \"cometer\", \"cometido\", \"perspectivas\", \"renunciara\", \"afect\\u00f3\", \"preguntas\", \"dieron\", \"Mi\", \"cambi\\u00f3\", \"posturas\", \"cometen\", \"primer\", \"acciones\", \"peque\\u00f1o\", \"Debi\\u00f3\", \"similares\", \"parecidas\", \"escuchar\", \"tenia\", \"sesi\\u00f3n\", \"sirvi\\u00f3\", \"debio\", \"respuestas\", \"error\", \"dio\", \"compa\\u00f1eros\", \"pudo\", \"opiniones\", \"postura\", \"haber\", \"renunciado\", \"haberse\", \"opini\\u00f3n\", \"errores\", \"problema\", \"aprender\", \"jefe\", \"experiencia\", \"renunciar\", \"grave\", \"adecuado\", \"puntos\", \"si\", \"decisi\\u00f3n\", \"No\", \"sido\", \"mejor\", \"creo\", \"Laura\", \"puede\", \"solo\", \"bien\", \"trabajo\", \"adem\\u00e1s\", \"Si\", \"Mantengo\", \"vez\", \"as\\u00ed\", \"pues\"], \"Freq\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0975090185976919, 0.06439901597125175, 0.05491011654771949, 0.08863883309860165, 0.05163158287381453, 0.3875228245942832, 0.02894615239666387, 0.070836907651743, 0.03170783017446466, 0.02335258657995032, 0.021249048245722935, 0.019587831399091593, 0.4677766667909182, 0.05182147849833951, 0.01879337606555831, 0.021071001927744915, 0.021607209736622335, 0.018807563358614665, 0.01583726802187413, 0.022748067466206168, 0.017940307184705295, 0.01721253633841613, 0.016139117867283947, 0.014257014670769674, 0.10702072353850678, 0.012946470240566166, 0.02557751227162841, 0.014769347953741851, 0.011840659755698701, 0.011243913131511019, 0.2874534897501455, 0.08464822842093556, 0.07546144196026594, 0.04333520391584633, 0.07636607284070296, 0.47878143547661267, 0.08875180821520345, 0.08824780147196698, 0.11281860531968846, 0.03171420814152115, 0.048302067562250084, 0.16211434270841174, 0.18095226531049757, 0.05417649096222288, 0.09210538599371088, 0.07366040750625968, 0.17547126715421602, 0.14254993928731974, 0.1572843843350622, 0.06636567308887775, 0.12095179131577272, 0.07159228628471093, 0.08839986231030394, 0.16903757332474356, 0.07805439078497534, 0.07201785696349594, 0.07166302428425686, 0.07144919248916626, 0.006420918197593519, 0.005616090251047787, 0.00426255037139903, 0.004147247824591013, 0.004004514239849811, 0.02011246880677524, 0.006446785243221603, 0.0034834176417303728, 0.0034675151051233866, 0.0034450121625252614, 0.0032954701070468002, 0.0038325873009831014, 0.003054679386912623, 0.003170704510633896, 0.002941201302976714, 0.0027812945839935134, 0.004057444898213344, 0.0032641785719140747, 0.0026666627927294014, 0.005201209147285047, 0.0027874700937194023, 0.004548571600935709, 0.005596186559238735, 0.002524786598388642, 0.0024962115939861536, 0.0027031222431433237, 0.002493123352080264, 0.0024968839080674824, 0.0023964488341996597, 0.005988795773576475, 0.00391901950054676, 0.04729741212215535, 0.023981171705853066, 0.005179976802321934, 0.006253090601786596, 0.004280503163987443, 0.006664486036600296, 0.004991357538008567, 0.004791468099947047, 0.004922905405438244, 0.006451553978105047, 0.006032868484490035, 0.008561911838218299, 0.007090207547416488, 0.0060755992946814295, 0.005772706118259963, 0.005777185354816878, 0.014577284181585187, 0.010862772065487608, 0.00817093246439183, 0.0156069366064409, 0.00977123869147601, 0.02493276166674699, 0.01134441467834986, 0.01404394955797722, 0.03367584490856315, 0.04653869740164571, 0.015989724307566205, 0.014091738991012945, 0.018715112205984832, 0.027983402298742188, 0.02103375300745719, 0.028743348263816887, 0.0158391228362737, 0.01584484890276991, 0.012251307344457507, 0.015100581824181836, 0.008029866125060077, 0.028333989058147796, 0.010246016726253734, 0.013193644268664442, 0.00995590589451617, 0.018540032345909133, 0.01628270752377642, 0.01392598697742059, 0.01262297410179302, 0.010917504782747778, 0.012999777798478426, 0.011152661584910947, 0.011056006548748144, 0.004065398099567963, 0.004954005232984476, 0.011089604308669634, 0.0024647885540741744, 0.014492479031162603, 0.004364676243583568, 0.011967541574590984, 0.002709242653593992, 0.0042801511584574375, 0.002317358502500571, 0.0019032189395759395, 0.0017745467999592361, 0.001773482592725837, 0.0016344327822457975, 0.0018693903175114532, 0.0019579741910478246, 0.002008802333685524, 0.001631152953227421, 0.0018223475283859585, 0.0014757008706998663, 0.011970550400787927, 0.0015439070692619995, 0.0013610601627425268, 0.0014088503811239307, 0.0015967776350866193, 0.0025677929046664487, 0.0014494934212492937, 0.0012835321620021049, 0.016780054149867857, 0.0012585860917095001, 0.0029476389714559806, 0.011473232428295982, 0.006685163612633396, 0.002323461625015063, 0.07631463911313796, 0.01798129569712248, 0.02343639626500227, 0.004861174606260434, 0.007222200870441106, 0.007201099478957834, 0.006310999050507318, 0.00704760070138169, 0.00940308982201725, 0.0051475995728707605, 0.011066344622921304, 0.0049958546699646125, 0.038155401690448065, 0.012946260620529337, 0.014020857685174803, 0.010020766401419148, 0.013526053785010927, 0.01269265201095754, 0.004903722744104548, 0.01447386183220914, 0.0073323836688457406, 0.00817705777051271, 0.006728107136645192, 0.009581463879084887, 0.0060666087061384405, 0.005946126410761268, 0.007284799047797136, 0.0014736472947696625, 0.0008251362959910665, 0.0006687835582725259, 0.0005265323492775844, 0.0005488460210896929, 0.00048619007197392775, 0.00027261542064489276, 0.0012151657991872752, 0.0009160121726687295, 0.00025686279378024104, 0.0004207117812623129, 0.00035478265818040893, 0.0003579169825245446, 0.0002368525502731845, 0.00025857888475300976, 0.000241545558841916, 0.00040889154954075295, 0.00022732981372311685, 0.00030789823617644214, 0.0002080958528329805, 0.00024041197291433856, 0.00018863736215355667, 0.00041546177297434295, 0.00021318110586518804, 0.0002420753662237317, 0.00024782298570851413, 0.0001697204593428236, 0.00020078210053906106, 0.00022648316271250849, 0.0006431832449959336, 0.008440528985709447, 0.0005091948466204302, 0.0008115503065353252, 0.0009145317772137063, 0.0012983105311992742, 0.0018992713674983886, 0.003049807242589542, 0.0008202822207170747, 0.00046851782621035024, 0.0016022649348667265, 0.00412850067627556, 0.0014405458422556174, 0.002530108433501937, 0.0012761496054087352, 0.0009737623496166433, 0.0026015430184391456, 0.000904474672632171, 0.0024620229380470163, 0.0005804836051424376, 0.0036212374863816635, 0.0017865615021343843, 0.0021482438370730786, 0.000943859871157473, 0.0018723514681313006, 0.0018169361722446585, 0.0020847463265745297, 0.001769598744770882, 0.0013354012225649248, 0.0016225533351124253, 0.0019033245412253645, 0.0010464167296268864, 0.0012348113050958407, 0.001007968651676447, 0.0011280776921609222, 0.0011232773153198221, 0.0010397976972343261], \"Total\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09763972391686744, 0.06451621090020743, 0.055021014918873276, 0.08881791111991137, 0.051738424558966725, 0.38880852637897584, 0.02905820816188883, 0.07114230766814071, 0.03184674571842906, 0.02345903750618019, 0.02135465971766155, 0.019693722314026513, 0.4703293875290401, 0.0521048434298428, 0.018899801597210393, 0.021190934075233325, 0.021735188190579045, 0.01892773324201237, 0.01594257637785209, 0.02291008228166355, 0.018068674238718267, 0.017339010254515213, 0.016259795551862105, 0.014363871852961297, 0.10787971661455399, 0.013051230384488343, 0.025794698868303895, 0.014896034702656403, 0.011945951480220858, 0.011350426329625582, 0.29519723791068503, 0.08588626525830548, 0.0764997642700735, 0.04380213277332738, 0.07801899471619046, 0.509755796057458, 0.09213626928613285, 0.09174296725562239, 0.11953269177798657, 0.03234083905140837, 0.05050599508736115, 0.18124499609019168, 0.20440217064092966, 0.057542368661262076, 0.10155672112676332, 0.08015536236967864, 0.20843868498640064, 0.16697165537527975, 0.18773501470332665, 0.07355211245893743, 0.1485855614634049, 0.08129843051402307, 0.10560142727433154, 0.257352909903219, 0.09397646775579963, 0.0853187275523447, 0.08610222659931974, 0.10563644497872542, 0.006606842179651549, 0.0058037411831608175, 0.004454786296614005, 0.004336754590989294, 0.00418954551618526, 0.021075853481175345, 0.0067722726574775925, 0.0036701151455920027, 0.0036533986098272833, 0.003630554409282612, 0.0034835062202447794, 0.004052602264418871, 0.003241648469115895, 0.003367374123099732, 0.003132430225066827, 0.0029719331844311175, 0.00433676022248694, 0.0034908299719401156, 0.0028520061891959903, 0.0055659823764668175, 0.0029840227492259576, 0.0048746568198347415, 0.0059984982353460704, 0.0027127501361663476, 0.0026828429564305905, 0.002910893377407017, 0.002686577504626445, 0.002692840827440722, 0.002586166542832005, 0.0064644826152783115, 0.004233451297835244, 0.05360020260993549, 0.026822388612732187, 0.005649116393725067, 0.006863801191644975, 0.004669986290436927, 0.007435875199067941, 0.005485420865478218, 0.005271717345257102, 0.005580934927690726, 0.007594312447214817, 0.007050882066307164, 0.010602041563474928, 0.008590775126225327, 0.007175036828310142, 0.006756975321455957, 0.006823848937304863, 0.0239082790699345, 0.016452581256153315, 0.011387610710519688, 0.03443050683064321, 0.01702322955583936, 0.07579298511156962, 0.021586659270551464, 0.03184908104318022, 0.14136539101970352, 0.257352909903219, 0.04441233899513121, 0.03826284290535722, 0.07704101151424199, 0.18773501470332665, 0.10563644497872542, 0.20843868498640064, 0.06759748505732843, 0.06951515987726478, 0.03871370821963501, 0.06810917867753377, 0.013916331432043428, 0.509755796057458, 0.028443397986371736, 0.06341850610230992, 0.02693028839370906, 0.20440217064092966, 0.1485855614634049, 0.10560142727433154, 0.07281391225382808, 0.04589787165566159, 0.18124499609019168, 0.05847614637869791, 0.057819461970713595, 0.004354145757072677, 0.005374727425439921, 0.012109601234511104, 0.002720707059855919, 0.016000970472728603, 0.0048189897185901606, 0.013273951779161231, 0.0030316421463333033, 0.004802608813498665, 0.002626885668933916, 0.0021678099360209323, 0.002035704160865239, 0.002042469246436425, 0.001890976730546892, 0.0021647823781965523, 0.0022704204806399753, 0.002338624258364995, 0.0019021939406850446, 0.0021325493714176844, 0.0017344080866322214, 0.014084083630885102, 0.0018306244982799265, 0.0016141993595340904, 0.0016711986244502593, 0.001904464042488892, 0.003075920249051877, 0.0017364626187283086, 0.0015411336639693284, 0.020178104963652153, 0.0015160035799313474, 0.0036409645637476536, 0.015034957259211773, 0.008823801862857748, 0.0028905110022774795, 0.14136539101970352, 0.028443397986371736, 0.03871370821963501, 0.006784785042501388, 0.011881286626950944, 0.012027287828837831, 0.010427592660175488, 0.013424623043097828, 0.022445411665024895, 0.010357029955385757, 0.03476501267667737, 0.009933792022790842, 0.257352909903219, 0.04598508577562117, 0.06951515987726478, 0.04441233899513121, 0.09397646775579963, 0.10563644497872542, 0.011882396660679749, 0.16697165537527975, 0.03424510510619702, 0.053376820512156406, 0.03148103093510292, 0.1485855614634049, 0.021409775280656074, 0.02240615729313373, 0.08019099602858772, 0.0018142814740878897, 0.001132942566513602, 0.0009814267725721474, 0.0007980575898296675, 0.0009463268388137291, 0.0009636972882334287, 0.0005411559398717566, 0.0024231460237770343, 0.0018298504201094104, 0.0005286079600324389, 0.0008761495940455333, 0.000755175637227283, 0.0007651210681374645, 0.000510191510917065, 0.0005579847708919218, 0.0005247208057009463, 0.0008924968348922663, 0.000500989155769344, 0.0006860469298132207, 0.0004782640856200337, 0.0005809752416468233, 0.00046331487776363146, 0.0010272107729900628, 0.0005379003423739766, 0.0006129676313715638, 0.0006276439715919794, 0.00043628217799575905, 0.0005193440904389721, 0.0005885332595757602, 0.001679106019130532, 0.0239082790699345, 0.0013868820432412512, 0.0022830958724555273, 0.0026648904130239567, 0.004585844296430566, 0.009208945872489969, 0.021203246464192173, 0.003355517675274837, 0.0015212777581653468, 0.01098348719728043, 0.05360020260993549, 0.009810168449850543, 0.026822388612732187, 0.008590775126225327, 0.005542565439452322, 0.03871370821963501, 0.005898966655722561, 0.06810917867753377, 0.0024576568077720297, 0.257352909903219, 0.04441233899513121, 0.07579298511156962, 0.008983224788529622, 0.06951515987726478, 0.08019099602858772, 0.18773501470332665, 0.1485855614634049, 0.04434645962290046, 0.16697165537527975, 0.509755796057458, 0.020236748573695944, 0.09397646775579963, 0.015076799252207328, 0.04681254470846279, 0.04589787165566159, 0.06130683496011435], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.8862, -5.3011, -5.4605, -4.9816, -5.522, -3.5064, -6.1007, -5.2058, -6.0096, -6.3155, -6.4098, -6.4913, -3.3182, -5.5184, -6.5327, -6.4183, -6.3931, -6.5319, -6.7038, -6.3417, -6.5791, -6.6205, -6.6849, -6.8089, -4.7931, -6.9053, -6.2244, -6.7736, -6.9946, -7.0463, -3.8051, -5.0277, -5.1425, -5.6972, -5.1306, -3.2949, -4.9803, -4.986, -4.7404, -6.0094, -5.5887, -4.3779, -4.2679, -5.4739, -4.9432, -5.1667, -4.2987, -4.5065, -4.4081, -5.271, -4.6708, -5.1952, -4.9843, -4.336, -5.1088, -5.1892, -5.1942, -5.1972, -6.2562, -6.3902, -6.6659, -6.6934, -6.7284, -5.1145, -6.2522, -6.8678, -6.8724, -6.8789, -6.9233, -6.7723, -6.9991, -6.9618, -7.037, -7.0929, -6.7152, -6.9328, -7.135, -6.4669, -7.0907, -6.601, -6.3937, -7.1896, -7.201, -7.1214, -7.2023, -7.2008, -7.2418, -6.3259, -6.75, -4.2593, -4.9385, -6.471, -6.2827, -6.6617, -6.219, -6.5081, -6.549, -6.5219, -6.2515, -6.3186, -5.9685, -6.1571, -6.3115, -6.3627, -6.3619, -5.4363, -5.7305, -6.0152, -5.3681, -5.8364, -4.8996, -5.6871, -5.4736, -4.599, -4.2755, -5.3439, -5.4702, -5.1865, -4.7842, -5.0697, -4.7574, -5.3533, -5.353, -5.6102, -5.4011, -6.0326, -4.7717, -5.7889, -5.5361, -5.8176, -5.1959, -5.3257, -5.482, -5.5803, -5.7254, -5.5509, -5.7041, -5.7128, -5.9055, -5.7078, -4.902, -6.4059, -4.6344, -5.8345, -4.8258, -6.3114, -5.854, -6.4676, -6.6645, -6.7345, -6.7351, -6.8167, -6.6824, -6.6361, -6.6105, -6.8187, -6.7079, -6.9189, -4.8256, -6.8737, -6.9998, -6.9653, -6.84, -6.365, -6.9368, -7.0584, -4.4878, -7.078, -6.227, -4.868, -5.4081, -6.465, -2.9732, -4.4187, -4.1537, -5.7268, -5.3309, -5.3338, -5.4657, -5.3553, -5.067, -5.6695, -4.9041, -5.6994, -3.6664, -4.7472, -4.6675, -5.0034, -4.7034, -4.767, -5.718, -4.6357, -5.3157, -5.2067, -5.4017, -5.0482, -5.5052, -5.5253, -5.3222, -5.116, -5.696, -5.9061, -6.1452, -6.1037, -6.2249, -6.8035, -5.3089, -5.5915, -6.863, -6.3696, -6.54, -6.5312, -6.9441, -6.8563, -6.9245, -6.3981, -6.9851, -6.6818, -7.0735, -6.9292, -7.1717, -6.3821, -7.0494, -6.9223, -6.8988, -7.2774, -7.1093, -6.9889, -5.9451, -3.3707, -6.1787, -5.7126, -5.5931, -5.2427, -4.8623, -4.3887, -5.7019, -6.2619, -5.0323, -4.0859, -5.1387, -4.5755, -5.2599, -5.5304, -4.5477, -5.6042, -4.6028, -6.0477, -4.217, -4.9235, -4.7391, -5.5615, -4.8766, -4.9066, -4.7691, -4.933, -5.2145, -5.0198, -4.8602, -5.4584, -5.2928, -5.4958, -5.3833, -5.3875, -5.4647], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3306, 0.3301, 0.3299, 0.3299, 0.3299, 0.3287, 0.3281, 0.3277, 0.3276, 0.3274, 0.327, 0.3266, 0.3265, 0.3265, 0.3263, 0.3263, 0.3261, 0.3256, 0.3253, 0.3249, 0.3248, 0.3246, 0.3245, 0.3245, 0.324, 0.3239, 0.3235, 0.3234, 0.3231, 0.3225, 0.3054, 0.3174, 0.3183, 0.3212, 0.3106, 0.2693, 0.2945, 0.2931, 0.2742, 0.3124, 0.2873, 0.2204, 0.2101, 0.2717, 0.2343, 0.2475, 0.1598, 0.1738, 0.155, 0.2292, 0.1262, 0.2048, 0.1542, -0.0884, 0.1463, 0.1625, 0.1484, -0.0591, 1.6538, 1.6495, 1.6382, 1.6376, 1.6372, 1.6355, 1.6331, 1.6301, 1.6301, 1.6299, 1.6268, 1.6265, 1.6229, 1.6221, 1.6193, 1.616, 1.6158, 1.6152, 1.6151, 1.6145, 1.6142, 1.6131, 1.6129, 1.6105, 1.6102, 1.6083, 1.6076, 1.6068, 1.6061, 1.6059, 1.6052, 1.5572, 1.5704, 1.5956, 1.5891, 1.5952, 1.5728, 1.5879, 1.5868, 1.5569, 1.5192, 1.5264, 1.4686, 1.4904, 1.516, 1.5249, 1.5158, 1.1876, 1.2672, 1.3504, 0.8911, 1.1272, 0.5705, 1.039, 0.8635, 0.2478, -0.0278, 0.6608, 0.6834, 0.2673, -0.2211, 0.0685, -0.2989, 0.2312, 0.2036, 0.5318, 0.1759, 1.1324, -1.2075, 0.6613, 0.1123, 0.6872, -0.7178, -0.5287, -0.3436, -0.0701, 0.2463, -0.9526, 0.0254, 0.028, 2.4215, 2.4086, 2.4021, 2.3913, 2.3911, 2.3911, 2.3865, 2.3777, 2.3749, 2.3647, 2.3599, 2.3528, 2.3489, 2.3443, 2.3434, 2.342, 2.3381, 2.3364, 2.3329, 2.3286, 2.3275, 2.3198, 2.3195, 2.3193, 2.3139, 2.3095, 2.3095, 2.3072, 2.3057, 2.304, 2.2788, 2.2197, 2.2125, 2.2717, 1.8736, 2.0315, 1.9882, 2.1567, 1.9923, 1.9771, 1.9879, 1.8457, 1.62, 1.791, 1.3454, 1.8028, 0.5813, 1.2226, 0.8891, 1.0012, 0.5517, 0.3711, 1.605, 0.0446, 0.9488, 0.614, 0.947, -0.2512, 1.229, 1.1635, 0.0915, 4.0864, 3.9773, 3.9108, 3.8785, 3.7496, 3.6102, 3.6087, 3.6042, 3.6024, 3.5727, 3.5608, 3.5389, 3.5346, 3.527, 3.5252, 3.5186, 3.5138, 3.5042, 3.4932, 3.4622, 3.412, 3.3958, 3.3891, 3.3688, 3.3653, 3.3651, 3.3502, 3.344, 3.3394, 3.3348, 3.2532, 3.2924, 3.26, 3.2249, 3.0324, 2.7157, 2.3553, 2.8856, 3.1166, 2.3694, 1.7307, 2.376, 1.9334, 2.3875, 2.5553, 1.5943, 2.4192, 0.9742, 2.8513, 0.0307, 1.0811, 0.731, 2.0412, 0.68, 0.5071, -0.206, -0.136, 0.7916, -0.3395, -1.296, 1.3322, -0.0378, 1.5891, 0.5687, 0.5842, 0.2175]}, \"token.table\": {\"Topic\": [], \"Freq\": [], \"Term\": []}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 2, 1, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el139161399683683792646414605639\", ldavis_el139161399683683792646414605639_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el139161399683683792646414605639\", ldavis_el139161399683683792646414605639_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el139161399683683792646414605639\", ldavis_el139161399683683792646414605639_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "vis_data = gensimvis.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (204,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/camilo/ethics-nlp/topic-modelling/TM_laura.ipynb Cell 15\u001b[0m in \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/camilo/ethics-nlp/topic-modelling/TM_laura.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mTM_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_lda_embeddings\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/camilo/ethics-nlp/topic-modelling/TM_laura.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/camilo/ethics-nlp/topic-modelling/TM_laura.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m arr_test \u001b[39m=\u001b[39m get_lda_embeddings(lda_model,tokenizador,dictionary,df_test,\u001b[39m'\u001b[39;49m\u001b[39mcomment\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/camilo/ethics-nlp/topic-modelling/TM_laura.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_topics \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(arr_test, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mTopic\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(topics))])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/camilo/ethics-nlp/topic-modelling/TM_laura.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df_topics[\u001b[39m'\u001b[39m\u001b[39msel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_test[\u001b[39m'\u001b[39m\u001b[39msel\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/ethics-nlp/topic-modelling/TM_utils.py:8\u001b[0m, in \u001b[0;36mget_lda_embeddings\u001b[0;34m(lda_model, tokenizer, dictionary, df_test, column)\u001b[0m\n\u001b[1;32m      6\u001b[0m doc_term_matrix \u001b[39m=\u001b[39m [dictionary\u001b[39m.\u001b[39mdoc2bow(bow) \u001b[39mfor\u001b[39;00m bow \u001b[39min\u001b[39;00m tokenized_test]\n\u001b[1;32m      7\u001b[0m topic_probs \u001b[39m=\u001b[39m lda_model\u001b[39m.\u001b[39mget_document_topics(doc_term_matrix)\n\u001b[0;32m----> 8\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49marray([[p[\u001b[39m1\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m p \u001b[39min\u001b[39;49;00m probs] \u001b[39mfor\u001b[39;49;00m probs \u001b[39min\u001b[39;49;00m topic_probs])\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (204,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from TM_utils import get_lda_embeddings\n",
    "import pandas as pd\n",
    "\n",
    "arr_test = get_lda_embeddings(lda_model,tokenizador,dictionary,df_test,'comment')\n",
    "df_topics = pd.DataFrame(arr_test, columns=['Topic{}'.format(i+1) for i in range(len(topics))])\n",
    "\n",
    "df_topics['sel'] = df_test['sel'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Only compute pearson prod-moment correlations between feature\n",
    "# columns and target column\n",
    "target_col_name = 'sel'\n",
    "feature_target_corr = {}\n",
    "for col in df_topics:\n",
    "    if target_col_name != col:\n",
    "        feature_target_corr[col + '_' + target_col_name] = \\\n",
    "            pearsonr(df_topics[col], df_topics[target_col_name])[0]\n",
    "print(\"Feature-Target Correlations\")\n",
    "print(feature_target_corr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethics_env",
   "language": "python",
   "name": "ethics_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
