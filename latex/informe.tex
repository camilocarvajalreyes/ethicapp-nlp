% Template:     Reporte LaTeX
% Documento:    Archivo principal
% Versión:      3.2.2 (12/03/2023)
% Codificación: UTF-8
%
% Autor: Pablo Pizarro R.
%        pablo@ppizarror.com
%
% Manual template: [https://latex.ppizarror.com/reporte]
% Licencia MIT:    [https://opensource.org/licenses/MIT]

% CREACIÓN DEL DOCUMENTO
\documentclass[
	spanish, % Idioma: spanish, english, etc.
	letterpaper, oneside
]{article}

% INFORMACIÓN DEL DOCUMENTO
\def\documenttitle {\textbf{Informe parcial} \\ Procesamiento de datos textuales EthicApp con algoritmos de procesamiento de lenguaje natural}
\def\documentsubtitle {}
\def\documentsubject {Tema a tratar}
\def\documentdate {30 de Marzo 2023 }

\def\documentauthor {Camilo Carvajal Reyes}
\def\coursename {Unidad de Ética}
\def\coursecode {}

\def\universityname {Universidad de Chile}
\def\universityfaculty {Facultad de Ciencias Físicas y Matemáticas}
\def\universitydepartment {Departamento de Ingeniería Matemática}
\def\universitydepartmentimage {departamentos/logo_ethics3}
\def\universitylocation {Santiago de Chile}

% IMPORTACIÓN DEL TEMPLATE
\input{template}

% INICIO DE PÁGINAS
\begin{document}
	
% CONFIGURACIÓN DE PÁGINA Y ENCABEZADOS
\templatePagecfg


% CONFIGURACIONES FINALES
\templateFinalcfg

% ======================= INICIO DEL DOCUMENTO =======================

% Título y nombre del autor
\inserttitle

\begin{abstract}
    La aplicaión \textit{EthicApp} es una herramienta que permite recolectar preferencias de estudiantes ante dilemas éticos y sus justificaciones. Lamentablemente, el gran volumen de datos (del orden de dos mil textos) dificulta el análisis de estos. Este trabajo aborda el uso de modelos de aprendizaje de máquina supervisados y no-supervisados para modelar la estructura textual de las respuestas y con esto apoyar el análisis que puedan hacer los equipos docentes. \color{red} Acá falta un resumen de los resultados y su pertinencia respecto al objetivo global. \color{black}
\end{abstract}


\section{Descripción de la problemática}

En el marco de la enseñanza de la formación ética en la FCFM, se ha utilizado la aplicación EthicApp para la obtención y posterior análisis de las decisiones morales de estudiantes ante un dilema ético. Estos casos de estudio consisten en una problemática, que se plantea en forma de pregunta. Como respuesta a esta pregunta, los estudiantes manifiestan una preferencia en la forma de un número entre 1 y 6, donde los extremos de esta escala representan posturas dispares en cuanto a la decisión a tomar.

\insertimage[\label{img:respuesta1}]{img/intro2}{scale=0.75}{Estructura de respuestas de estudiantes.}

Luego de una primera respuesta se realiza una instancia de deliberación grupal, donde se toma una nueva decisión en conjunto. Finalmente, los estudiantes otorgan nuevamente una calificación, que puede diferir de la señalada en las dos instancias anteriores.

\insertimage[\label{img:respuesta2}]{img/intro4}{scale=0.75}{Iteraciones de las respuestas de estudiantes.}

\newp El Área de Ética de la FCFM ha llevado a cabo un completo análisis de las posturas de los estudiantes. No obstante, un aspecto difícil de procesar son las justificaciones que deben colocar luego de cada instancia de decisión. Pese a que análisis cualitativos de algunas respuestas han permitido plantear hipótesis preliminares respecto a los juicios morales y justificaciones de las decisiones, la gran magnitud de datos presentes dificultan la tarea de tomar conclusiones acerca de las competencias éticas exprimidas en la instancia, y como consecuencia la verificación de la adquisición de esta durante los cursos formativos de la escuela.


\section{Proposición de solución}

La ciencia de datos es una disciplina en constante crecimiento, en particular en nuestra facultad. En particular, los métodos basados en aprendizaje de máquinas han experimentado un aumento considerable en sus capacidades, ayudado por la mejora en capacidad de cómputo en las últimas décadas. Los algoritmos de procesamiento han sido una demostración de aquello, con modelos conversacionales como \textit{chatGPT} tomando protagonismo entre los medios y el público. 

\newp Dentro de esta rama se encuentran los modelos de lenguaje, que intentan aproximar modelar uno o más lenguajes humanos al inducir una probabilidad a secuencias de palabras (frases, oraciones o documentos). Estos modelos se implementan usando redes neuronales profundas y siendo entrenados en grandes volúmenes de datos textuales (córpuses). Finalmente, un modelo sirve para resolver variadas tareas de procesamiento de texto, incluyendo clasificación, pregunta-respuesta e categorización/identificación de elementos relevantes de una secuencia. Entre las desventajas que presentan estos modelos están su costo de entrenamiento y capacidad limitada de interpretabilidad, ambas consecuencias de su gran tamaño.

\newp Se propone la implementación de estos modelos pero también el uso de algoritmos más simples y más interpretables, para procesar los argumentos escritos por estudiantes en sus decisiones éticas. Más precisamente, se procederá a:

\begin{enumerate}
    \item Explorar las justificaciones textuales de las respuestas usando técnicas de minería de datos.

    \item Implementar modelos estadísticos para texto, que sean interpretables, para predecir la respuesta (número en la escala de 1 a 6) de los estudiantes utilizando el texto de justificación.

    \insertimage[\label{img:modelo1}]{img/modelo1}{scale=0.75}{Ejemplo de modelo para predecir posturas de estudiantes.}

    \item Implementar los modelos anteriormente descritos para la predicción del cambio de respuesta de una etapa a otra, usando las justificaciones de la etapa intermedia y última etapa.

    \insertimage[\label{img:modelo2}]{img/modelo2}{scale=0.75}{Ejemplo de modelo para predecir cambios de postura.}
    
    \item Identificar, a través del texto, elementos semánticos que justifiquen los argumentos dados por los estudiantes. Esto usando tanto el análisis exploratorio de datos como los algoritmos.
    
    \item Identificar, del mismo modo que el punto anterior, elementos semánticos en cambios de valoraciones entre distintas etapas de la actividad, tanto con elementos diferentes como comunes entre ambas justificaciones.

    \item Implementar modelos de lenguaje entrenados con aprendizaje profundo para las dos tareas de predicción anteriores. Comparar la capacidad de predicción tanto con los algoritmos básicos como con la capacidad humana.
    
    \item Utilizar modelos predictivos de texto para predecir el grado de competencia ética en las justificaciones, utilizando tanto técnicas simples como avanzadas de procesamiento de lenguaje natural.(*)

    \item Utilizar modelos de reconocimiento de entidades para la identificación automática de elementos textuales que denoten elementos positivos y negativos en cuanto a la calidad de la respuesta otorgada.(*)

    \insertimage[\label{img:modelo3}]{img/modelo3}{scale=0.7}{Ejemplo de modelo para asistencia a la evaluación de competencia ética.}
\end{enumerate}

\\ (*) Notar que estas tareas requieren la creación de un dataset con etiquetas especiales.

\newp Si es que los modelos muestran una buena capacidad de predicción, se pueden usar como herramienta que a la larga servirá para evaluar la progresión de competencia ética de los estudiantes con menor inversión humana. Esto es de particular relevancia para los objetivos finales del área de ética. Por otro lado, existe un interés en verificar hasta que punto los algoritmos pueden modelar relaciones semánticas complejas como lo son las justificaciones morales de estudiantes ante a una problemática. Este es un objetivo complementario y que logrará plantear nuevas perspectivas de investigación cualquiera sea el resultado, tanto del punto de vista computacional como del estudio de la ética.

\newp Este proyecto consistirá de la utilización de diversas técnicas de modelamiento de lenguaje que permitan tomar una fotografía global de las justificaciones de estudiantes antes las preferencias escogidas.
De manera sistemática se considerarán los datos del caso Adela, a modo de no sobrecargar el informe de información. No obstante, los códigos para cada caso pueden encontrarse en el \href{https://github.com/camilocarvajalreyes/ethics-nlp}{repositorio de github del trabajo}. Se provee un resumen del caso Adela a continuación:

\newp \textit{En Chile, la deficiencia de vitamina D es un problema serio tanto en adultos mayores como en niños. Para abordar esta preocupante situación, un grupo de profesionales creó una startup que encontró una fruta ancestral de las comunidades diaguitas con alta concentración de vitamina D. Adela, una ingeniera del equipo, diseña el proceso de producción de un nuevo alimento a base de esta fruta. Sin embargo, se enfrenta a desafíos, ya que el árbol solo crece cerca de los ríos y necesita abundante luz solar, lo que dificulta llevarlo a zonas más australes afectadas por la sequía. Además, para conservar la vitamina D durante el transporte, el equipo decide liofilizar la fruta y agregar conservantes. Aunque aún no tienen la obligación legal de integrar a las comunidades diaguitas en el proyecto, Adela escucha sus preocupaciones sobre cómo estos cambios afectarían sus tradiciones. Aunque los cambios son necesarios para ayudar a quienes sufren deficiencia de vitamina D, las comunidades prefieren mantener sus prácticas tradicionales, ya que estas son parte fundamental de su identidad.}

Adela debería priorizar:
\begin{itemize}
    \item[(1)] Preservar el recurso natural/resguardar tradiciones
    \item[(6)] Producir el alimento contra el déficit vitamínico
\end{itemize}


\section{Estado del arte}

El procesamiento del lenguaje natural (NLP) ha ganado la atención de los medios y la sociedad en general en los últimos meses. Los últimos modelos conversacionales como chatGPT han generado mucha atención del público. A pesar de las capacidades que han demostrado, este tipo de modelos no son capaces de procesar ideas de la misma manera que lo hacen los humanos. Este es especialmente el caso de las decisiones que implican juicios morales.

% Responding to a question ethically has thus being studied in the context of large language models in order to improve their capability of assisting human beings. Moreover, when training models to predict human like responses to ethical problems and other general NLP tasks, we are sometimes able to detect patterns and structures that might explain how different cultures carry out morality.
\newp En este contexto, responder éticamente a una pregunta se ha estudiado en el contexto de grandes modelos de lenguaje para mejorar su capacidad de ayudar a los seres humanos. Además, cuando entrenamos modelos para predecir respuestas similares a las humanas a dilemas éticos y otras tareas generales de NLP, a veces somos capaces de detectar patrones y estructuras que podrían explicar cómo las diferentes culturas enfrentan problemas morales.

% In this report we will analyse different articles that involve both morality and computational semantics. These works range from training models for prediction, analysis of moral judgements on social media, corpora and datasets containing ethical responses and linguistic resources that might help processing large amounts of text.
\newp En este informe analizaremos diferentes artículos que involucran tanto la moralidad como la semántica computacional. Estos trabajos van desde modelos de entrenamiento para la predicción, análisis de juicios morales en redes sociales, corpus y conjuntos de datos que contienen respuestas éticas y recursos lingüísticos que pueden ayudar a procesar grandes cantidades de texto.


\subsection{Modelos de lenguaje aprendiendo valores humanos}

Los modelos de lenguaje se han convertido en herramientas útiles a la hora de enfrentar diversas tareas de procesamiento de lenguaje, en especial aquellos que han sido entrenados en grandes corpuses de texto. Su capacidad de codificar de antemano elementos del lenguaje y naturaleza humana en su etapa de entrenamiento ha sido puesta a prueba también para predecir juicios morales humanos. Jentzsch et al. testean un modelo de estas características para predecir juicios usando simplemente similitudes de representaciones, mostrando que decisiones naturalmente humanas aparecen codificadas naturalmente \cite{use}.

\newp En esta dirección, han habido iniciativas de verificar la capacidad que esta familia de modelos tendrían para imitar el razonamiento moral humano. Por un lado Jin et al. entrenan un modelo en un dataset de preguntas y respuestas morales \cite{Jin}. El método usado combina ciencias de la cognición con semántica computacional al intentar construir una cadena de pensamientos morales. Los relatados sugieren que es necesario incorporar elementos de razonamiento humano, y se sugieren lineas de investigación posteriores al respecto.

\newp Otro ejemplo importante es \textit{Delphi} propuesto por Jiang et al., un modelo cuyo objetivo principal es imitar el proceso de pensamiento ético de los humanos \cite{Jiang}. Este modelo ha logrado consistencia en casos donde modelos de lenguaje suelen fallar, especialmente en dilemas nunca antes observados por el modelo. Se propone su uso paralelo a modelos de lenguaje y tiene un prototipo de investigación disponible en linea \footnote{\url{https://delphi.allenai.org/}}. Sus capacidades han sido puestas a prueba, argumentándose que sus capacidades efectivamente imitan aquellas que son propias de los grupos culturales que aportaron a las anotaciones de entrenamiento \cite{Fraser}. Naturalmente, existen críticas al proceso de entrenar modelos para cuestiones morales. Albrecht et al. argumentan que si bien ciertos modelos suelen tener métricas de desempeño similares a las de los seres humanos, esta no refleja un razonamiento o entendimiento de la problemática en cuestión \cite{Albrecht}. Una muestra de esto es pedirle justificación a modelos conversacionales, en donde se desprenden justificaciones que resultan ser poco éticas.


\subsection{Datasets que contienen decisiones o juzgamientos morales}

En el contexto de los modelos previamente mencionados y, más generalmente, para ampliar la capacidad de exploración en el área, se han propuesto varios datasets que exploran las respuestas humanas a cuestiones morales en distintos formatos.

\begin{itemize}
    \item MoralExceptQA: un dataset que consiste en preguntas y respuestas de excepciones morales \cite{Jin}.
    \item ETHICS dataset: un benchmark que incluye conceptos de justicia, bienestar, deberes, virtudes y moralidad de sentido común \cite{Hen}.
    \item Datset basado en el foro ``AmITheAsshole'' (AITA) del sitio web Reddit \cite{aita}.
    \item Moral Foundations Twitter Corpus: un colección de 35108 tweets procesado para siete categorias de discurso y anotado a mano por anotadores entrenados para 10 categorías de sentimiento moral \cite{Hoover}, siguiendo la teoría de fundamentos morales (ver sección \ref{section:rec}).
    \item SCRUPLES: un dataset con 625000 juzgamientos éticos de más de 32000 anécdotas de la vida real \cite{Lourie}.
    \item The Moral Machine: dataset con decisiones morales de personas de todas partes del mundo, en el contexto específico de decisiones morales que debe seguir la conducción automática de vehículos \cite{MM}.
\end{itemize}


\subsection{Recursos psico-linguisticos}
\label{section:rec}

Más allá del aprendizaje automático, la extracción de elementos que den muestra del razonamiento moral detrás de texto escrito por humano lleva siendo investigado por un tiempo. Uno de los marcos teóricos que ha tenido más influencia en este contexto ha sido la \textbf{teoría de fundamentos morales} (TFM), propuesta por Haidt y Graham \cite{tmf,tmf2}. Esta teoría de psicología social propone la existencia de fundamentos morales innatos y universales que afectan los juicios éticos de las personas. Estos incluyen: cuidado/daño, equidad/trampa, lealtad/fraude, autoridad/subversión, santidad/degradación y libertad/opresión. Se plantea la presencia de estos elementos en distintas culturas, pese a la evolución de estos. Las diferencias en comportamientos y creencias éticas (y como consecuencia distintos compartimientos grupales e ideologías) son resultado del enfasis que se le da a algunos fundamentos por sobre otros.

\newp En este contexto, se han desarrollado recursos semánticos como el diccionario de fundamentos morales (DFM por sus siglas en inglés), que mide el grado en el que ciertas palabras reflejan los seis fundamentos morales planteados en la TFM \cite{tfd}. En este se incluyen palabras reacionadas a los fundamentos y se les asigna un puntaje de acuerdo  la frecuencia de uso y grado de lenguaje moral empleado. El diccionario se ha usado en varios estudios para examinar el contenido moral de varios textos, tales como discursos, artículos y mensajes de redes sociales. 

\newp El TFD ha sido extendido tanto usando métodos semi-automáticos \cite{tfde}, usando anotadores para registrar las probabilidades de pertenencia a los fundamentos \cite{etfd}, como también usando otras herramientas semánticas como \textit{wordnet}\footnote{Wordnet es una base de datos lexical para el idoma inglés: ´\url{https://wordnet.princeton.edu/}} \cite{moral_strength}. Estos recursos pueden usarse tanto para detectar directamente palabras en texto que corresponda a las distintas dimensiones morales, como para complementar el trabajo de clasificadores automáticos en distintas tareas que pueden ser favorecidas por tener conocimiento directo de palabras con valor moral.


\subsection{Modelos que buscan predecir comportamiento humano}

Varios son los trabajos que buscan la predicción/identificación de elementos morales en texto natural. En esta sección abordaremos algunos de ellos. Primeramente, Garten et al. 2016 busca la detección automática de retóricas morales \cite{garten}. Para esto usan el diccionario de fundamentos morales \cite{tfd}, combinado con representaciones de palabras distribuidas. Estas últimas, más conocidas por su traducción en inglés \textit{word embeddings}, corresponden a asignar un vector fijo a cada palabra. Estos vectores suelen ser obtenidos usando redes neuronales, siguiendo la hipótesis distribucional, que nos dice que palabras con significado similar aparecerán en contextos similares (y por ende deben tener una representación vectorial similar). Otro trabajo que usa categorías provenientes de la TFM es el de Xie et al. que evalua modelos en la clasificación de dilemas morales en los distintos fundamentos, gracias a lo cual concluyen que modelos de lenguaje tienen ventaja sobre modelos como las representaciones distribucionales \cite{xie}.

\newp Por otro lado, Kennedy et al. buscan la predicción de preocupaciones morales propias a un individuo usando evidencias de lenguaje moral escritas por este \cite{diff}. Los datos usados consisten en estados de Facebook de usuarios que hayan contestado el cuestionario de fundamentos morales, basados en la teoría del mismo nombre mencionada anteriormente. Se utilizaron distintas técnicas de procesamiento de lenguaje para predecir los puntajes obtenidos por los usuarios, para cada una de las dimensiones morales planteadas en la TFM. Se destacan la variedad de métodos para vectorizar texto testeados, incluyendo \textit{latent dirichlet allocation} (LDA) \cite{lda}, \textit{word embeddings}, conteo de ocurrencias del DFM \cite{tfd} y BERT \cite{bert}, que corresponde a un modelo de lenguaje profundo. Es este último que obtiene mejores resultados. Finalmente, tanto conteos de diccionario como LDA se usaron para interpretar que elementos linguísticos específicos explicaban cada fundamento por separado.

\newp Igualmente en la linea de la utilización de redes sociales, trabajos recientes hen hecho uso del dataset AITA del sitio \textit{Reddit} \cite{aita}. En la comunidad en cuestión, un usuario expone su problemática, para que luego los usuarios juzguen si es que es culposo o no. Alhassan et al. por un lado intentan predecir el resultado final (veredicto con más votos) usando el texto del usuario original \cite{alh}. Por otro lado, Botzer et al. utilizan los comentarios para entrenar un clasificador que dirime entre una valoración positiva o negativa del actuar del usuario en la situación \cite{botzer}. Efstathiadis et al. además de clasificar tanto posts como comentarios, exploran patrones que emergen desde el texto y desde los clasificadores mismos \cite{Efs}. Estos trabajos hacen uso de modelos de lenguaje pre-entrenados como BERT \cite{bert}.


Los trabajos mencionados en este reporte muestran la alta variedad de formatos en los cuales se ha evaluado la presencia y grado de categorías morales, así como también la capacidad de distintos modelos de procesamiento de lenguaje natural para modelarlos. No obstante, ninguno de los artículos estudiados enfrenta un desafío tan específico como el nuestro. Los datos que poseemos tienen la ventaja de poder verse desde distintos ángulos, lo cual plantea dificultades pero también abre puertas a que las conclusiones que se puedan tomar sean reflejo de nuevos descubrimientos en el área. Para finalizar, muchos de los artículos nos confirman la pertinencia de los modelos a usar, en el caso de modelos de lenguaje, y nos sugieren algunos tipos de modelos más simples que tengan capacidad interpretativa.


\section{Análisis exploratorio de datos}

\insertimagerightline[\label{figure:freq}]{img/tabla_2022.png}{0.5}{6}{Frecuencias por caso.}

Un análisis exploratorio adecuado se vuelve particularmente relevante a la hora de tomar conclusiones acerca de los datos textuales. Nos remitiremos al reporte de los largos de texto y $n$-gramas más frecuentes tanto de manera global como restringiéndonos a la etapa a evaluar o postura escogida por los estudiantes. A modo informativo se incluyen las frecuencias para cada uno de los casos en la figura \ref{figure:freq}.

\newp En la figura \ref{figure:tokens} se observan los $n$-gramas más frecuentes para $n \in \{ 1, 3 \}$. Se ignoraron los $2$-gramas pues en general eran concatenaciones de dos palabras que carecían de significado sin tener una tercera. En el caso de los $1$-gramas, i.e., palabras más frecuentes, destacan ``agua'', ``recursos'' y ``tradiciones'', que son elementos importantes en el platemiento del dilema.

\begin{images}[\label{figure:tokens}]{Visualización de textos más frecuentes del dataset para el caso Adela}
    \addimage{adela/1_gramas_adela}{width=6.5cm}{1-gramas más frecuentes}
    \addimage{adela/3_gramas_adela}{width=8.5cm}{3-gramas más frecuentes}
    \imagesnewline
    \addimage{adela/nube_adela}{width=12cm}{Nube de palabras}
\end{images}

\begin{images}[\label{figure:largos}]{Visualización de largos de texto para caso Adela, con y sin \textit{stop-words}.}
    \addimage{adela/hist_largo_adela}{width=7.5cm}{Histogramas de largo de texto}
    \addimage{adela/boxplot_largo_adela}{width=7.5cm}{Boxplot de largos de texto}
\end{images}

\insertimagerightline[\label{figure:freq_postura}]{img/adela/freq_adela.png}{0.65}{19}{Frecuencias de posturas por etapa en caso Adela}

En cuanto a los largos en general de los textos para el caso, estos son incluidos en la figura \ref{figure:largos}. Los largos de mensaje tienen un promedio de palabras inferior al $50\%$ para el caso Adela. También se incluye la cantidad de palabras que son relevantes dentro del texto. Para esto, se removieron las llamadas \textit{stop-words}, que son palabras que no aportan información al mensaje y solo contribuyen a la grámaica de este (algunos ejemplos incluyen ciertos artículos y conjunciones). 

\newp Las frecuencias de cada elección son mostradas en la figura \ref{figure:freq_postura}, donde se aprecia el hecho de que no hay un cambio brusco entre una etapa y otra, en especial entre las etapas individual 1 e individual 2. Recordemos que entre medio de esas existe una etapa grupal, para la cual se observa una mayor frecuencia de la postura (3), lo cual puede deberse al hecho de que estudiantes con posiciones similares están tratando de llegar a un consenso para colocar la valoración, lo cual por contraste disminuye la frecuencia de posiciones ``extremas'' como (1) y (6).

\subsection{Condicionamiento a selección de postura y etapa de actividad}

Una hipótesis a considerar en cuanto al rol del largo de palabras en la postura de estudiantes es que aquellas posiciones extremas tendrán una explicación más larga en extensión para explicarla. Por el contrario, se observa un efecto inverso, donde las posturas (1) y (6) tienen menor largo promedio que las preferencias más moderadas. Esto puede responder al hecho de que una persona absolutamente convencida de su postura vea menos necesidad de explicar esta. De cualquier modo la diferencia es sutil, por ende no se usará la variable implícita de largo de texto para las tareas de aprendizaje, pues se postula que aportará poca información.

\insertimage[\label{img:boxplot_largo_sel}]{img/adela/boxplot_largo_sel_adela}{scale=0.5}{Boxplots de largos de texto para cada elección de postura.}

\insertimagerightline[\label{figure:patterns}]{img/adela/1_gramas_sel_adela.png}{0.7}{16}{Frecuencias de posturas por etapa en caso Adela}

\newp Por otro lado, las palabras más frecuentes por cada postura se condicen con la justificación más comúnmente utilizada en cada caso. Se aprecia por ejemplo que para apoyar la producción del alimente se evoca... \color{red} COMPLETAR INFO \color{black}.

\insertimage[\label{img:modelo3}]{img/adela/boxplot_largo_etapa_adela}{scale=0.5}{Boxplots de largos de texto para cada etapa de la actividad.}



\section{Metodología}

\subsection{Predicción supervisada de posturas con \textit{Naive-Bayes}}

Los métodos de Naive Bayes son un conjunto de algoritmos de aprendizaje supervisado basados en la aplicación del teorema de Bayes con la suposición ``naive'' de independencia condicional entre cada par de características dadas las clases variables. Consideramos vectores de $n$ dimensiones de ocurrencias introducidas anteriormente, cada uno correspondiente a un documento sobre un vocabulario de longitud $n$. Dado (un documento) $x=(x_1,\dots,x_n)$, nos gustaría etiquetarlo con una de las siguientes etiquetas: $C_1,\dots,C_k,\dots,C_K$. Gracias al teorema de Bayes, se tiene que:

$\forall k \in \{1,\dots,K\}$
%$$ \mathbb{P}(C_k|x_1,\dots,x_n)=\displaystyle\frac{\mathbb{P}(C_k)\mathbb{P}(x_1,\dots,x_n|C_k)}{\mathbb{P}(x_1,\dots,x_n)}$$
\begin{alignat*}{2}
    \mathbb{P}(C_k|x_1,\dots,x_n) & = \displaystyle\frac{\mathbb{P}(C_k)\mathbb{P}(x_1,\dots,x_n|C_k)}{\mathbb{P}(x_1,\dots,x_n)}\\
                                    & \propto \mathbb{P}(C_k)\mathbb{P}(x_1,\dots,x_n|C_k)
\end{alignat*}

El término $\mathbb{P}(C_k)$ se puede estimar con la frecuencia de la etiqueta $C_k$ en los datos. Para calcular la probabilidad de verosimilitud $\mathbb{P}(x_1,\dots,x_n|C_k)$, primero asumimos una distribución de probabilidad (como la Gaussiana o Multinomial). En el caso de clasificación binaria ($k\in{0,1}$) utilizando una distribución de Bernoulli, obtenemos, para cada característica $j$ (palabra):

$$ \mathbb{P}(x_j|C_k) = \mathbb{P}(j|C_k)x_j + (1-\mathbb{P}(j|C_k))(1-x_j)$$

$\mathbb{P}(j|C_k)$ también se puede estimar, tomando la proporción de documentos que contienen la palabra $j$ entre los de clase $C_k$. Este modelo permite la detección de spam y el análisis de sentimientos, y tiene un rendimiento aceptable en el caso de textos cortos \cite{bayes}. Además, es posible interpretar la probabilidad que cada palabra le asigna a cada clase. En efecto, ese vector de probabilidad discreto nos permite identificar que palabras son las que más ``empujan'' hacia alguna elección en específico.


\subsection{Modelamiento no supervisado con \textit{Latent Dirichlet Allocation}}

\insertimagerightline[\label{figure:patterns}]{img/LDA.png}{0.7}{11}{Diagrama de un modelo de tópicos LDA aplicado a texto.}

La modelización de tópicos (\textit{topic modelling} en ingles) se refiere a un tipo de modelado estadístico en el procesamiento del lenguaje natural que tiene como objetivo extraer la estructura semántica oculta de un texto. La suposición subyacente es que un documento está compuesto por una mezcla de temas abstractos, y los métodos existentes infieren esos temas basándose en las palabras de cada documento. La Asignación Latente de Dirichlet (LDA, por sus siglas en inglés) es el modelo de temas más ampliamente utilizado. Los documentos se representan como mezclas aleatorias de temas latentes. De manera similar, los temas se caracterizan por una distribución sobre todas las palabras.


% \subsection{Modelos de lenguajes profundos}
% https://www.overleaf.com/project/623ddd7aeb06ec285ddc6300


\section{Resultados}

\subsection{Tarea de clasificación}

\lipsum[7]

\begin{table}[htbp]
\centering
\caption{Resultados de clasificación de posturas para caso Adela}
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{}    & \textbf{precision} & \textbf{recall} & \textbf{f1-score} & \textbf{support} \\ \hline
1            & 0.39               & 0.23            & 0.29              & 203              \\ \hline
2            & 0.56               & 0.63            & 0.59              & 629              \\ \hline
3            & 0.42               & 0.40            & 0.41              & 406              \\ \hline
4            & 0.28               & 0.31            & 0.29              & 221              \\ \hline
5            & 0.32               & 0.38            & 0.35              & 142              \\ \hline
6            & 0.09               & 0.05            & 0.06              & 44               \\ \hline
accuracy     &                    &                 & 0.44              & 1645             \\ \hline
macro avg    & 0.34               & 0.33            & 0.33              & 1645             \\ \hline
weighted avg & 0.43               & 0.44            & 0.44              & 1645             \\ \hline
\end{tabular}
\end{table}

\insertimage[\label{img:modelo3}]{img/adela/nb_adela_cm}{scale=0.75}{Matriz de confusión de clasificación caso Adela.}

\subsubsection{Clasificación Binaria}

\begin{table}[htbp]
\centering
\caption{Resultados de clasificación binaria de posturas para caso Adela}
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{}    & \textbf{precision} & \textbf{recall} & \textbf{f1-score} & \textbf{support} \\ \hline
1            & 0.83               & 0.94            & 0.89              & 1239              \\ \hline
6            & 0.71               & 0.43            & 0.54              & 406               \\ \hline
accuracy     &                    &                 & 0.82              & 1645             \\ \hline
macro avg    & 0.77               & 0.69            & 0.71              & 1645             \\ \hline
weighted avg & 0.80               & 0.82            & 0.80              & 1645             \\ \hline
\end{tabular}
\end{table}


\subsection{Interpretabilidad de modelos}

\begin{table}[htbp]
\centering
\caption{Palabras con más probabilidad por cada clase}
\begin{tabular}{l|ll|ll|}
\cline{2-5}
                                & \multicolumn{2}{l|}{\textbf{Producir el alimento}}                       & \multicolumn{2}{l|}{\textbf{Resguardar tradiciones/recurso}}            \\ \hline
\multicolumn{1}{|l|}{\textbf{}} & \multicolumn{1}{l|}{\textbf{Palabra}}               & \textbf{Probabilidad} & \multicolumn{1}{l|}{\textbf{Palabra}}              & \textbf{Probabilidad} \\ \hline
\multicolumn{1}{|l|}{1}         & \multicolumn{1}{l|}{\textit{\textbf{localidad}}}    & 0.9668010706219343 & \multicolumn{1}{l|}{\textit{\textbf{ancestral}}}   & 0.8854034049522704 \\ \hline
\multicolumn{1}{|l|}{2}         & \multicolumn{1}{l|}{\textit{\textbf{agotar}}}       & 0.9655681541235328 & \multicolumn{1}{l|}{\textit{\textbf{siglos}}}      & 0.8225615683211234 \\ \hline
\multicolumn{1}{|l|}{3}         & \multicolumn{1}{l|}{\textit{\textbf{renovable}}}    & 0.9642401314198153 & \multicolumn{1}{l|}{\textit{\textbf{llevarlo}}}    & 0.6986026158057846 \\ \hline
\multicolumn{1}{|l|}{4}         & \multicolumn{1}{l|}{\textit{\textbf{limitado}}}     & 0.9612510695138682 & \multicolumn{1}{l|}{\textit{\textbf{propiedades}}} & 0.6899382168962785 \\ \hline
\multicolumn{1}{|l|}{5}         & \multicolumn{1}{l|}{\textit{\textbf{escasea}}}      & 0.9595609803445707 & \multicolumn{1}{l|}{\textit{\textbf{pasen}}}       & 0.6759654794382005 \\ \hline
\multicolumn{1}{|l|}{6}         & \multicolumn{1}{l|}{\textit{\textbf{parecer}}}      & 0.9577167362530623 & \multicolumn{1}{l|}{\textit{\textbf{pasando}}}     & 0.657596180886742  \\ \hline
\multicolumn{1}{|l|}{7}         & \multicolumn{1}{l|}{\textit{\textbf{hablando}}}     & 0.9577167362530623 & \multicolumn{1}{l|}{\textit{\textbf{adele}}}       & 0.6496517790919291 \\ \hline
\multicolumn{1}{|l|}{8}         & \multicolumn{1}{l|}{\textit{\textbf{causar}}}       & 0.9577167362530623 & \multicolumn{1}{l|}{\textit{\textbf{cultivado}}}   & 0.6326032091783609 \\ \hline
\multicolumn{1}{|l|}{9}         & \multicolumn{1}{l|}{\textit{\textbf{perjudicaría}}} & 0.9534729522199789 & \multicolumn{1}{l|}{\textit{\textbf{ingeniera}}}   & 0.613810540612241  \\ \hline
\multicolumn{1}{|l|}{10}        & \multicolumn{1}{l|}{\textit{\textbf{escaso}}}       & 0.9525198782868932 & \multicolumn{1}{l|}{\textit{\textbf{hacen}}}       & 0.613810540612241  \\ \hline
\end{tabular}
\end{table}


\subsection{Modelamiento de tópicos}

\lipsum[8]

\insertimage[\label{img:modelo3}]{img/adela/LDA_viz}{scale=0.4}{Visualización de tópicos ajustados con LDA.}


\section{Conclusiones}

\lipsum[9]

\iffalse
\begin{images}[\label{figure:glove}]{Descripción general}
    \addimage{img1}{width=5.5cm}{}
    \addimage{img2}{width=5.3cm}{}
    \imagesnewline
    \addimage{img3}{width=9cm}{}
\end{images}
\fi


% -------------------------------------------------------------------------------------------

\begin{references}

    \bibitem{bayes}
    Metsis, V., Androutsopoulos, I.,  Paliouras, G. (2006, July). Spam filtering with naive bayes-which naive bayes?. In CEAS(Vol. 17, pp. 28-69)

    \bibitem{use} Jentzsch, S., Schramowski, P., Rothkopf, C., & Kersting, K. (2019). Semantics Derived Automatically from Language Corpora Contain Human-like Moral Choices. Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society, 37–44. \url{https://doi.org/10.1145/3306618.3314267}

    \bibitem{Jin} Jin, Z., Levine, S., Gonzalez Adauto, F., Kamal, O., Sap, M., Sachan, M., Mihalcea, R., Tenenbaum, J., & Schölkopf, B. (2022). When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment. Advances in Neural Information Processing Systems, 35, 28458–28473. \url{https://openreview.net/forum?id=uP9RiC4uVcR}

    \bibitem{Jiang} Jiang, L., Hwang, J. D., Bhagavatula, C., Bras, R. L., Liang, J., Dodge, J., Sakaguchi, K., Forbes, M., Borchardt, J., Gabriel, S., Tsvetkov, Y., Etzioni, O., Sap, M., Rini, R., & Choi, Y. (2022). Can Machines Learn Morality? The Delphi Experiment (arXiv:2110.07574). arXiv. \url{https://doi.org/10.48550/arXiv.2110.07574}

    \bibitem{Fraser} Fraser, K. C., Kiritchenko, S., & Balkir, E. (2022). Does Moral Code have a Moral Code? Probing Delphi’s Moral Philosophy. Proceedings of the 2nd Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), 26–42. \url{https://doi.org/10.18653/v1/2022.trustnlp-1.3}

    \bibitem{Albrecht} Albrecht, J., Kitanidis, E., & Fetterman, A. J. (2022). Despite ‘super-human’ performance, current LLMs are unsuited for decisions about ethics and safety (arXiv:2212.06295). arXiv. \url{https://doi.org/10.48550/arXiv.2212.06295}

    \bibitem{Hen} Hendrycks, D., Burns, C., Basart, S., Critch, A., Li, J., Song, D., & Steinhardt, J. (2023, April 2). Aligning AI With Shared Human Values. International Conference on Learning Representations. \url{https://openreview.net/forum?id=dNy_RKzJacY}

    \bibitem{aita} O’Brien, E. (2020, February 17). AITA for making this? A public dataset of Reddit posts about moral dilemmas (BLOG post). Developer Tools for Machine Learning | Iterative. \url{https://iterative.ai/blog/a-public-reddit-dataset/}

    \bibitem{Hoover} Hoover, J., Portillo-Wightman, G., Yeh, L., Havaldar, S., Davani, A. M., Lin, Y., ... & Dehghani, M. (2020). Moral foundations twitter corpus: A collection of 35k tweets annotated for moral sentiment. Social Psychological and Personality Science, 11(8), 1057-1071. \url{https://doi.org/10.1177/1948550619876629}

    \bibitem{Lourie} Lourie, N., Le Bras, R., & Choi, Y. (2021, May). Scruples: A corpus of community ethical judgments on 32,000 real-life anecdotes. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 35, No. 15, pp. 13470-13479).

    \bibitem{MM} Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., Shariff, A., Bonnefon, J.-F., & Rahwan, I. (2018). The Moral Machine experiment. Nature, 563(7729), Article 7729. \url{https://doi.org/10.1038/s41586-018-0637-6}

    \bibitem{tmf} Haidt, J. (2007). The New Synthesis in Moral Psychology. Science, 316(5827), 998–1002. \url{https://doi.org/10.1126/science.1137651}

    \bibitem{tmf2} Graham, J., Haidt, J., Koleva, S., Motyl, M., Iyer, R., Wojcik, S. P., & Ditto, P. H. (2013). Chapter Two - Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism. In P. Devine & A. Plant (Eds.), Advances in Experimental Social Psychology (Vol. 47, pp. 55–130). Academic Press. \url{https://doi.org/10.1016/B978-0-12-407236-7.00002-4}

    \bibitem{tfd} Graham, J., Haidt, J., & Nosek, B. A. (2009). Liberals and conservatives rely on different sets of moral foundations. Journal of Personality and Social Psychology, 96, 1029–1046. \url{https://doi.org/10.1037/a0015141}

    \bibitem{tfde} Rezapour, R., Shah, S. H., & Diesner, J. (2019). Enhancing the Measurement of Social Effects by Capturing Morality. Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, 35–45. \url{https://doi.org/10.18653/v1/W19-1305}

    \bibitem{etfd} Hopp, F. R., Fisher, J. T., Cornell, D., Huskey, R., & Weber, R. (2021). The extended Moral Foundations Dictionary (eMFD): Development and applications of a crowd-sourced approach to extracting moral intuitions from text. Behavior Research Methods, 53(1), 232–246. \url{https://doi.org/10.3758/s13428-020-01433-0}

    \bibitem{moral_strength} Araque, O., Gatti, L., & Kalimeri, K. (2020). MoralStrength: Exploiting a moral lexicon and embedding similarity for moral foundations prediction. Knowledge-Based Systems, 191(C). \url{https://doi.org/10.1016/j.knosys.2019.105184}

    \bibitem{garten} Garten, J., Boghrati, R., Hoover, J., Johnson, K. M., & Dehghani, M. (2016). Morality Between the Lines: Detecting Moral Sentiment In Text. Proceedings of IJCAI 2016 Workshop on Computational Modeling of Attitudes.

    \bibitem{xie} Xie, J. Y., Hirst, G., & Xu, Y. (2020). Contextualized moral inference (arXiv:2008.10762). arXiv. \url{https://doi.org/10.48550/arXiv.2008.10762}

    \bibitem{diff} Kennedy, B., Atari, M., Mostafazadeh Davani, A., Hoover, J., Omrani, A., Graham, J., & Dehghani, M. (2021). Moral concerns are differentially observable in language. Cognition, 212, 104696. \url{https://doi.org/10.1016/j.cognition.2021.104696}

    \bibitem{lda} Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation. The Journal of Machine Learning Research, 3(null), 993–1022.

    \bibitem{bert} Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171–4186. \url{https://doi.org/10.18653/v1/N19-1423}

    \bibitem{alh} Alhassan, A., Zhang, J., & Schlegel, V. (2022). `Am I the Bad One’? Predicting the Moral Judgement of the Crowd Using Pre–trained Language Models. Proceedings of the Thirteenth Language Resources and Evaluation Conference, 267–276. \url{https://aclanthology.org/2022.lrec-1.28}

    \bibitem{botzer} Botzer, N., Gu, S., & Weninger, T. (2022). Analysis of Moral Judgment on Reddit. IEEE Transactions on Computational Social Systems, 1–11. \url{https://doi.org/10.1109/TCSS.2022.3160677}

    \bibitem{Efs} Efstathiadis, I. S., Paulino-Passos, G., & Toni, F. (2022). Explainable patterns for distinction and prediction of moral judgement on reddit. \url{https://arxiv.org/pdf/2201.11155.pdf}

\end{references}



% FIN DEL DOCUMENTO
\end{document}