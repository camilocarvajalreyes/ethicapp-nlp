% Template:     Reporte LaTeX
% Documento:    Archivo principal
% Versión:      3.2.2 (12/03/2023)
% Codificación: UTF-8
%
% Autor: Pablo Pizarro R.
%        pablo@ppizarror.com
%
% Manual template: [https://latex.ppizarror.com/reporte]
% Licencia MIT:    [https://opensource.org/licenses/MIT]

% CREACIÓN DEL DOCUMENTO
\documentclass[
	spanish, % Idioma: spanish, english, etc.
	letterpaper, oneside
]{article}

% INFORMACIÓN DEL DOCUMENTO
\def\documenttitle {\textbf{Informe parcial} \\ Procesamiento de datos textuales EthicApp con algoritmos de procesamiento de lenguaje natural}
\def\documentsubtitle {}
\def\documentsubject {Tema a tratar}
\def\documentdate {30 de Marzo 2023 }

\def\documentauthor {Camilo Carvajal Reyes}
\def\coursename {Unidad de Ética}
\def\coursecode {}

\def\universityname {Universidad de Chile}
\def\universityfaculty {Facultad de Ciencias Físicas y Matemáticas}
\def\universitydepartment {Departamento de Ingeniería Matemática}
\def\universitydepartmentimage {departamentos/logo_ethics3}
\def\universitylocation {Santiago de Chile}

% IMPORTACIÓN DEL TEMPLATE
\input{template}

% INICIO DE PÁGINAS
\begin{document}
	
% CONFIGURACIÓN DE PÁGINA Y ENCABEZADOS
\templatePagecfg

% CONFIGURACIONES FINALES
\templateFinalcfg

% ======================= INICIO DEL DOCUMENTO =======================

% Título y nombre del autor
\inserttitle

\begin{abstract}
    La aplicaión \textit{EthicApp} es una herramienta que permite recolectar preferencias de estudiantes ante dilemas éticos y sus justificaciones. Lamentablemente, el gran volumen de datos (del orden de dos mil textos) dificulta el análisis de estos. Este trabajo aborda el uso de modelos de aprendizaje de máquina supervisados y no-supervisados para modelar la estructura textual de las respuestas y con esto apoyar el análisis que puedan hacer los equipos docentes. \color{red} Acá falta un resumen de los resultados y su pertinencia respecto al objetivo global. \color{black}
\end{abstract}


\section{Descripción de la problemática}

En el marco de la enseñanza de la formación ética en la FCFM, se ha utilizado la aplicación EthicApp para la obtención y posterior análisis de las decisiones morales de estudiantes ante un dilema ético. Estos casos de estudio consisten en una problemática, que se plantea en forma de pregunta. Como respuesta a esta pregunta, los estudiantes manifiestan una preferencia en la forma de un número entre 1 y 6, donde los extremos de esta escala representan posturas dispares en cuanto a la decisión a tomar.

\insertimage[\label{img:respuesta1}]{img/intro2}{scale=0.75}{Estructura de respuestas de estudiantes.}

Luego de una primera respuesta se realiza una instancia de deliberación grupal, donde se toma una nueva decisión en conjunto. Finalmente, los estudiantes otorgan nuevamente una calificación, que puede diferir de la señalada en las dos instancias anteriores.

\insertimage[\label{img:respuesta2}]{img/intro4}{scale=0.75}{Iteraciones de las respuestas de estudiantes.}

\newp El Área de Ética de la FCFM ha llevado a cabo un completo análisis de las posturas de los estudiantes. No obstante, un aspecto difícil de procesar son las justificaciones que deben colocar luego de cada instancia de decisión. Pese a que análisis cualitativos de algunas respuestas han permitido plantear hipótesis preliminares respecto a los juicios morales y justificaciones de las decisiones, la gran magnitud de datos presentes dificultan la tarea de tomar conclusiones acerca de las competencias éticas exprimidas en la instancia, y como consecuencia la verificación de la adquisición de esta durante los cursos formativos de la escuela.


\section{Proposición de solución}

La ciencia de datos es una disciplina en constante crecimiento, en particular en nuestra facultad. En particular, los métodos basados en aprendizaje de máquinas han experimentado un aumento considerable en sus capacidades, ayudado por la mejora en capacidad de cómputo en las últimas décadas. Los algoritmos de procesamiento han sido una demostración de aquello, con modelos conversacionales como \textit{chatGPT} tomando protagonismo entre los medios y el público. 

\newp Dentro de esta rama se encuentran los modelos de lenguaje, que intentan aproximar modelar uno o más lenguajes humanos al inducir una probabilidad a secuencias de palabras (frases, oraciones o documentos). Estos modelos se implementan usando redes neuronales profundas y siendo entrenados en grandes volúmenes de datos textuales (córpuses). Finalmente, un modelo sirve para resolver variadas tareas de procesamiento de texto, incluyendo clasificación, pregunta-respuesta e categorización/identificación de elementos relevantes de una secuencia. Entre las desventajas que presentan estos modelos están su costo de entrenamiento y capacidad limitada de interpretabilidad, ambas consecuencias de su gran tamaño.

\newp Se propone la implementación de estos modelos pero también el uso de algoritmos más simples y más interpretables, para procesar los argumentos escritos por estudiantes en sus decisiones éticas. Más precisamente, se procederá a:

\begin{enumerate}
    \item Explorar las justificaciones textuales de las respuestas usando técnicas de minería de datos.

    \item Implementar modelos estadísticos para texto, que sean interpretables, para predecir la respuesta (número en la escala de 1 a 6) de los estudiantes utilizando el texto de justificación.

    \insertimage[\label{img:modelo1}]{img/modelo1}{scale=0.75}{Ejemplo de modelo para predecir posturas de estudiantes.}

    \item Implementar los modelos anteriormente descritos para la predicción del cambio de respuesta de una etapa a otra, usando las justificaciones de la etapa intermedia y última etapa.

    \insertimage[\label{img:modelo2}]{img/modelo2}{scale=0.75}{Ejemplo de modelo para predecir cambios de postura.}
    
    \item Identificar, a través del texto, elementos semánticos que justifiquen los argumentos dados por los estudiantes. Esto usando tanto el análisis exploratorio de datos como los algoritmos.
    
    \item Identificar, del mismo modo que el punto anterior, elementos semánticos en cambios de valoraciones entre distintas etapas de la actividad, tanto con elementos diferentes como comunes entre ambas justificaciones.

    \item Implementar modelos de lenguaje entrenados con aprendizaje profundo para las dos tareas de predicción anteriores. Comparar la capacidad de predicción tanto con los algoritmos básicos como con la capacidad humana.
    
    \item Utilizar modelos predictivos de texto para predecir el grado de competencia ética en las justificaciones, utilizando tanto técnicas simples como avanzadas de procesamiento de lenguaje natural.(*)

    \item Utilizar modelos de reconocimiento de entidades para la identificación automática de elementos textuales que denoten elementos positivos y negativos en cuanto a la calidad de la respuesta otorgada.(*)

    \insertimage[\label{img:modelo3}]{img/modelo3}{scale=0.75}{Ejemplo de modelo para asistencia a la evaluación de competencia ética.}
\end{enumerate}

Si es que los modelos muestran una buena capacidad de predicción, se pueden usar como herramienta que a la larga servirá para evaluar la progresión de competencia ética de los estudiantes con menor inversión humana. Esto es de particular relevancia para los objetivos finales del área de ética. Por otro lado, existe un interés en verificar hasta que punto los algoritmos pueden modelar relaciones semánticas complejas como lo son las justificaciones morales de estudiantes ante a una problemática. Este es un objetivo complementario y que logrará plantear nuevas perspectivas de investigación cualquiera sea el resultado, tanto del punto de vista computacional como del estudio de la ética.

\\ (*) Notar que estas tareas requieren la creación de un dataset con etiquetas especiales.


\section{Estado del arte}

El procesamiento del lenguaje natural (NLP) ha ganado la atención de los medios y la sociedad en general en los últimos meses. Los últimos modelos conversacionales como chatGPT han generado mucha atención del público. A pesar de las capacidades que han demostrado, este tipo de modelos no son capaces de procesar ideas de la misma manera que lo hacen los humanos. Este es especialmente el caso de las decisiones que implican juicios morales.

% Responding to a question ethically has thus being studied in the context of large language models in order to improve their capability of assisting human beings. Moreover, when training models to predict human like responses to ethical problems and other general NLP tasks, we are sometimes able to detect patterns and structures that might explain how different cultures carry out morality.
\newp En este contexto, responder éticamente a una pregunta se ha estudiado en el contexto de grandes modelos de lenguaje para mejorar su capacidad de ayudar a los seres humanos. Además, cuando entrenamos modelos para predecir respuestas similares a las humanas a dilemas éticos y otras tareas generales de NLP, a veces somos capaces de detectar patrones y estructuras que podrían explicar cómo las diferentes culturas enfrentan problemas morales.

% In this report we will analyse different articles that involve both morality and computational semantics. These works range from training models for prediction, analysis of moral judgements on social media, corpora and datasets containing ethical responses and linguistic resources that might help processing large amounts of text.
\newp En este informe analizaremos diferentes artículos que involucran tanto la moralidad como la semántica computacional. Estos trabajos van desde modelos de entrenamiento para la predicción, análisis de juicios morales en redes sociales, corpus y conjuntos de datos que contienen respuestas éticas y recursos lingüísticos que pueden ayudar a procesar grandes cantidades de texto.


\subsection{Modelos de lenguaje aprendiendo valores humanos}

Los modelos de lenguaje se han convertido en herramientas útiles a la hora de enfrentar diversas tareas de procesamiento de lenguaje, en especial aquellos que han sido entrenados en grandes corpuses de texto. Su capacidad de codificar de antemano elementos del lenguaje y naturaleza humana en su etapa de entrenamiento ha sido puesta a prueba también para predecir juicios morales humanos. Jentzsch et al. testean un modelo de estas características para predecir juicios usando simplemente similitudes de representaciones, mostrando que decisiones naturalmente humanas aparecen codificadas naturalmente \cite{use}.

\newp En esta dirección, han habido iniciativas de verificar la capacidad que esta familia de modelos tendrían para imitar el razonamiento moral humano. Por un lado Jin et al. entrenan un modelo en un dataset de preguntas y respuestas morales \cite{Jin}. El método usado combina ciencias de la cognición con semántica computacional al intentar construir una cadena de pensamientos morales. Los relatados sugieren que es necesario incorporar elementos de razonamiento humano, y se sugieren lineas de investigación posteriores al respecto.

\newp Otro ejemplo importante es \textit{Delphi} propuesto por Jiang et al., un modelo cuyo objetivo principal es imitar el proceso de pensamiento ético de los humanos \cite{Jiang}. Este modelo ha logrado consistencia en casos donde modelos de lenguaje suelen fallar, especialmente en dilemas nunca antes observados por el modelo. Se propone su uso paralelo a modelos de lenguaje y tiene un prototipo de investigación disponible en linea \footnote{\url{https://delphi.allenai.org/}}. Sus capacidades han sido puestas a prueba, argumentándose que sus capacidades efectivamente imitan aquellas que son propias de los grupos culturales que aportaron a las anotaciones de entrenamiento \cite{Fraser}. Naturalmente, existen críticas al proceso de entrenar modelos para cuestiones morales. Albrecht et al. argumentan que si bien ciertos modelos suelen tener métricas de desempeño similares a las de los seres humanos, esta no refleja un razonamiento o entendimiento de la problemática en cuestión \cite{Albrecht}. Una muestra de esto es pedirle justificación a modelos conversacionales, en donde se desprenden justificaciones que resultan ser poco éticas.


\subsection{Datasets que contienen decisiones o juzgamientos morales}

En el contexto de los modelos previamente mencionados y, más generalmente, para ampliar la capacidad de exploración en el área, se han propuesto varios datasets que exploran las respuestas humanas a cuestiones morales en distintos formatos.

\begin{itemize}
    \item MoralExceptQA: un dataset que consiste en preguntas y respuestas de excepciones morales \cite{Jin}.
    \item ETHICS dataset: un benchmark que incluye conceptos de justicia, bienestar, deberes, virtudes y moralidad de sentido común \cite{Hen}.
    \item Datset basado en el foro ``AmITheAsshole'' (AITA) del sitio web Reddit \cite{aita}.
    \item Moral Foundations Twitter Corpus: un colección de 35108 tweets procesado para siete categorias de discurso y anotado a mano por anotadores entrenados para 10 categorías de sentimiento moral \cite{Hoover}, siguiendo la teoría de fundamentos morales (ver sección \ref{section:rec}).
    \item SCRUPLES: un dataset con 625000 juzgamientos éticos de más de 32000 anécdotas de la vida real \cite{Lourie}.
    \item The Moral Machine: dataset con decisiones morales de personas de todas partes del mundo, en el contexto específico de decisiones morales que debe seguir la conducción automática de vehículos \cite{MM}.
\end{itemize}


\subsection{Recursos psico-linguisticos}
\label{section:rec}

Más allá del aprendizaje automático, la extracción de elementos que den muestra del razonamiento moral detrás de texto escrito por humano lleva siendo investigado por un tiempo. Uno de los marcos teóricos que ha tenido más influencia en este contexto ha sido la \textbf{teoría de fundamentos morales} (TFM), propuesta por Haidt y Graham \cite{tmf,tmf2}. Esta teoría de psicología social propone la existencia de fundamentos morales innatos y universales que afectan los juicios éticos de las personas. Estos incluyen: cuidado/daño, equidad/trampa, lealtad/fraude, autoridad/subversión, santidad/degradación y libertad/opresión. Se plantea la presencia de estos elementos en distintas culturas, pese a la evolución de estos. Las diferencias en comportamientos y creencias éticas (y como consecuencia distintos compartimientos grupales e ideologías) son resultado del enfasis que se le da a algunos fundamentos por sobre otros.

\newp En este contexto, se han desarrollado recursos semánticos como el diccionario de fundamentos morales (DFM por sus siglas en inglés), que mide el grado en el que ciertas palabras reflejan los seis fundamentos morales planteados en la TFM \cite{tfd}. En este se incluyen palabras reacionadas a los fundamentos y se les asigna un puntaje de acuerdo  la frecuencia de uso y grado de lenguaje moral empleado. El diccionario se ha usado en varios estudios para examinar el contenido moral de varios textos, tales como discursos, artículos y mensajes de redes sociales. 

\newp El TFD ha sido extendido tanto usando métodos semi-automáticos \cite{tfde}, usando anotadores para registrar las probabilidades de pertenencia a los fundamentos \cite{etfd}, como también usando otras herramientas semánticas como \textit{wordnet}\footnote{Wordnet es una base de datos lexical para el idoma inglés: ´\url{https://wordnet.princeton.edu/}} \cite{moral_strength}. Estos recursos pueden usarse tanto para detectar directamente palabras en texto que corresponda a las distintas dimensiones morales, como para complementar el trabajo de clasificadores automáticos en distintas tareas que pueden ser favorecidas por tener conocimiento directo de palabras con valor moral.


\subsection{Modelos que buscan predecir comportamiento humano}

Varios son los trabajos que buscan la predicción/identificación de elementos morales en texto natural. En esta sección abordaremos algunos de ellos. Primeramente, Garten et al. 2016 busca la detección automática de retóricas morales \cite{garten}. Para esto usan el diccionario de fundamentos morales \cite{tfd}, combinado con representaciones de palabras distribuidas. Estas últimas, más conocidas por su traducción en inglés \textit{word embeddings}, corresponden a asignar un vector fijo a cada palabra. Estos vectores suelen ser obtenidos usando redes neuronales, siguiendo la hipótesis distribucional, que nos dice que palabras con significado similar aparecerán en contextos similares (y por ende deben tener una representación vectorial similar). Otro trabajo que usa categorías provenientes de la TFM es el de Xie et al. que evalua modelos en la clasificación de dilemas morales en los distintos fundamentos, gracias a lo cual concluyen que modelos de lenguaje tienen ventaja sobre modelos como las representaciones distribucionales \cite{xie}.

\newp Por otro lado, Kennedy et al. buscan la predicción de preocupaciones morales propias a un individuo usando evidencias de lenguaje moral escritas por este \cite{diff}. Los datos usados consisten en estados de Facebook de usuarios que hayan contestado el cuestionario de fundamentos morales, basados en la teoría del mismo nombre mencionada anteriormente. Se utilizaron distintas técnicas de procesamiento de lenguaje para predecir los puntajes obtenidos por los usuarios, para cada una de las dimensiones morales planteadas en la TFM. Se destacan la variedad de métodos para vectorizar texto testeados, incluyendo \textit{latent dirichlet allocation} (LDA) \cite{lda}, \textit{word embeddings}, conteo de ocurrencias del DFM \cite{tfd} y BERT \cite{bert}, que corresponde a un modelo de lenguaje profundo. Es este último que obtiene mejores resultados. Finalmente, tanto conteos de diccionario como LDA se usaron para interpretar que elementos linguísticos específicos explicaban cada fundamento por separado.

\newp Igualmente en la linea de la utilización de redes sociales, trabajos recientes hen hecho uso del dataset AITA del sitio \textit{Reddit} \cite{aita}. En la comunidad en cuestión, un usuario expone su problemática, para que luego los usuarios juzguen si es que es culposo o no. Alhassan et al. por un lado intentan predecir el resultado final (veredicto con más votos) usando el texto del usuario original \cite{alh}. Por otro lado, Botzer et al. utilizan los comentarios para entrenar un clasificador que dirime entre una valoración positiva o negativa del actuar del usuario en la situación \cite{botzer}. Efstathiadis et al. además de clasificar tanto posts como comentarios, exploran patrones que emergen desde el texto y desde los clasificadores mismos \cite{Efs}. Estos trabajos hacen uso de modelos de lenguaje pre-entrenados como BERT \cite{bert}.


Los trabajos mencionados en este reporte muestran la alta variedad de formatos en los cuales se ha evaluado la presencia y grado de categorías morales, así como también la capacidad de distintos modelos de procesamiento de lenguaje natural para modelarlos. No obstante, ninguno de los artículos estudiados enfrenta un desafío tan específico como el nuestro. Los datos que poseemos tienen la ventaja de poder verse desde distintos ángulos, lo cual plantea dificultades pero también abre puertas a que las conclusiones que se puedan tomar sean reflejo de nuevos descubrimientos en el área. Para finalizar, muchos de los artículos nos confirman la pertinencia de los modelos a usar, en el caso de modelos de lenguaje, y nos sugieren algunos tipos de modelos más simples que tengan capacidad interpretativa.


\section{Análisis exploratorio de datos}

\lipsum[1]

\newp \lipsum[2]

\newp \lipsum[3]


\section{Metodología}

\subsection{Predicción supervisada de posturas con \textit{Naive-Bayes}}

\lipsum[4]


\subsection{Modelamiento no supervisado con \textit{Latent Dirichlet Allocation}}

\lipsum[5]


% \subsection{Modelos de lenguajes profundos}


\section{Resultados}

\subsection{Tarea de regresión}

\lipsum[6]


\subsection{Tarea de clasificación}

\lipsum[7]


% \subsection{Predicción de cambios de postura}

% \lipsum[8]


\section{Conclusiones}

\lipsum[9]


% -------------------------------------------------------------------------------------------

\begin{references}

    \bibitem{use} Jentzsch, S., Schramowski, P., Rothkopf, C., & Kersting, K. (2019). Semantics Derived Automatically from Language Corpora Contain Human-like Moral Choices. Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society, 37–44. \url{https://doi.org/10.1145/3306618.3314267}

    \bibitem{Jin} Jin, Z., Levine, S., Gonzalez Adauto, F., Kamal, O., Sap, M., Sachan, M., Mihalcea, R., Tenenbaum, J., & Schölkopf, B. (2022). When to Make Exceptions: Exploring Language Models as Accounts of Human Moral Judgment. Advances in Neural Information Processing Systems, 35, 28458–28473. \url{https://openreview.net/forum?id=uP9RiC4uVcR}

    \bibitem{Jiang} Jiang, L., Hwang, J. D., Bhagavatula, C., Bras, R. L., Liang, J., Dodge, J., Sakaguchi, K., Forbes, M., Borchardt, J., Gabriel, S., Tsvetkov, Y., Etzioni, O., Sap, M., Rini, R., & Choi, Y. (2022). Can Machines Learn Morality? The Delphi Experiment (arXiv:2110.07574). arXiv. \url{https://doi.org/10.48550/arXiv.2110.07574}

    \bibitem{Fraser} Fraser, K. C., Kiritchenko, S., & Balkir, E. (2022). Does Moral Code have a Moral Code? Probing Delphi’s Moral Philosophy. Proceedings of the 2nd Workshop on Trustworthy Natural Language Processing (TrustNLP 2022), 26–42. \url{https://doi.org/10.18653/v1/2022.trustnlp-1.3}

    \bibitem{Albrecht} Albrecht, J., Kitanidis, E., & Fetterman, A. J. (2022). Despite ‘super-human’ performance, current LLMs are unsuited for decisions about ethics and safety (arXiv:2212.06295). arXiv. \url{https://doi.org/10.48550/arXiv.2212.06295}

    \bibitem{Hen} Hendrycks, D., Burns, C., Basart, S., Critch, A., Li, J., Song, D., & Steinhardt, J. (2023, April 2). Aligning AI With Shared Human Values. International Conference on Learning Representations. \url{https://openreview.net/forum?id=dNy_RKzJacY}

    \bibitem{aita} O’Brien, E. (2020, February 17). AITA for making this? A public dataset of Reddit posts about moral dilemmas (BLOG post). Developer Tools for Machine Learning | Iterative. \url{https://iterative.ai/blog/a-public-reddit-dataset/}

    \bibitem{Hoover} Hoover, J., Portillo-Wightman, G., Yeh, L., Havaldar, S., Davani, A. M., Lin, Y., ... & Dehghani, M. (2020). Moral foundations twitter corpus: A collection of 35k tweets annotated for moral sentiment. Social Psychological and Personality Science, 11(8), 1057-1071. \url{https://doi.org/10.1177/1948550619876629}

    \bibitem{Lourie} Lourie, N., Le Bras, R., & Choi, Y. (2021, May). Scruples: A corpus of community ethical judgments on 32,000 real-life anecdotes. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 35, No. 15, pp. 13470-13479).

    \bibitem{MM} Awad, E., Dsouza, S., Kim, R., Schulz, J., Henrich, J., Shariff, A., Bonnefon, J.-F., & Rahwan, I. (2018). The Moral Machine experiment. Nature, 563(7729), Article 7729. \url{https://doi.org/10.1038/s41586-018-0637-6}

    \bibitem{tmf} Haidt, J. (2007). The New Synthesis in Moral Psychology. Science, 316(5827), 998–1002. \url{https://doi.org/10.1126/science.1137651}

    \bibitem{tmf2} Graham, J., Haidt, J., Koleva, S., Motyl, M., Iyer, R., Wojcik, S. P., & Ditto, P. H. (2013). Chapter Two - Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism. In P. Devine & A. Plant (Eds.), Advances in Experimental Social Psychology (Vol. 47, pp. 55–130). Academic Press. \url{https://doi.org/10.1016/B978-0-12-407236-7.00002-4}

    \bibitem{tfd} Graham, J., Haidt, J., & Nosek, B. A. (2009). Liberals and conservatives rely on different sets of moral foundations. Journal of Personality and Social Psychology, 96, 1029–1046. \url{https://doi.org/10.1037/a0015141}

    \bibitem{tfde} Rezapour, R., Shah, S. H., & Diesner, J. (2019). Enhancing the Measurement of Social Effects by Capturing Morality. Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, 35–45. \url{https://doi.org/10.18653/v1/W19-1305}

    \bibitem{etfd} Hopp, F. R., Fisher, J. T., Cornell, D., Huskey, R., & Weber, R. (2021). The extended Moral Foundations Dictionary (eMFD): Development and applications of a crowd-sourced approach to extracting moral intuitions from text. Behavior Research Methods, 53(1), 232–246. \url{https://doi.org/10.3758/s13428-020-01433-0}

    \bibitem{moral_strength} Araque, O., Gatti, L., & Kalimeri, K. (2020). MoralStrength: Exploiting a moral lexicon and embedding similarity for moral foundations prediction. Knowledge-Based Systems, 191(C). \url{https://doi.org/10.1016/j.knosys.2019.105184}

    \bibitem{garten} Garten, J., Boghrati, R., Hoover, J., Johnson, K. M., & Dehghani, M. (2016). Morality Between the Lines: Detecting Moral Sentiment In Text. Proceedings of IJCAI 2016 Workshop on Computational Modeling of Attitudes.

    \bibitem{xie} Xie, J. Y., Hirst, G., & Xu, Y. (2020). Contextualized moral inference (arXiv:2008.10762). arXiv. \url{https://doi.org/10.48550/arXiv.2008.10762}

    \bibitem{diff} Kennedy, B., Atari, M., Mostafazadeh Davani, A., Hoover, J., Omrani, A., Graham, J., & Dehghani, M. (2021). Moral concerns are differentially observable in language. Cognition, 212, 104696. \url{https://doi.org/10.1016/j.cognition.2021.104696}

    \bibitem{lda} Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation. The Journal of Machine Learning Research, 3(null), 993–1022.

    \bibitem{bert} Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 4171–4186. \url{https://doi.org/10.18653/v1/N19-1423}

    \bibitem{alh} Alhassan, A., Zhang, J., & Schlegel, V. (2022). `Am I the Bad One’? Predicting the Moral Judgement of the Crowd Using Pre–trained Language Models. Proceedings of the Thirteenth Language Resources and Evaluation Conference, 267–276. \url{https://aclanthology.org/2022.lrec-1.28}

    \bibitem{botzer} Botzer, N., Gu, S., & Weninger, T. (2022). Analysis of Moral Judgment on Reddit. IEEE Transactions on Computational Social Systems, 1–11. \url{https://doi.org/10.1109/TCSS.2022.3160677}

    \bibitem{Efs} Efstathiadis, I. S., Paulino-Passos, G., & Toni, F. (2022). Explainable patterns for distinction and prediction of moral judgement on reddit. \url{https://arxiv.org/pdf/2201.11155.pdf}

\end{references}



% FIN DEL DOCUMENTO
\end{document}